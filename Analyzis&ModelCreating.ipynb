{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –ü—Ä–æ–µ–∫—Ç - –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω–∞—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –û–ø–∏—Å–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞\n",
    "\n",
    "–ö–æ–º–ø–∞–Ω–∏—è –æ–Ω–ª–∞–π–Ω-—Å–µ—Ä–≤–∏—Å —Å –≤—ã—Å–æ–∫–∏–º —É—Ä–æ–≤–Ω–µ–º –≤—Ö–æ–¥—è—â–µ–≥–æ —Ç—Ä–∞—Ñ–∏–∫–∞ –∏–º–µ–µ—Ç —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ç–¥–µ–ª –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏, –∫–æ—Ç–æ—Ä—ã–π –∑–∞–Ω–∏–º–∞–µ—Ç—Å—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π –∏ –∞–Ω–∞–ª–∏–∑–æ–º —Ç—Ä–∞—Ñ–∏–∫–∞. –°–æ—Ç—Ä—É–¥–Ω–∏–∫–∏ —ç—Ç–æ–≥–æ –æ—Ç–¥–µ–ª–∞ –æ–±—Ä–∞—Ç–∏–ª–∏—Å—å –∑–∞ –ø–æ–º–æ—â—å—é –≤ –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏–∏ –≤—ã—è–≤–ª–µ–Ω–∏—è –∞–Ω–æ–º–∞–ª—å–Ω–æ–≥–æ –∏ –∑–ª–æ–Ω–∞–º–µ—Ä–µ–Ω–Ω–æ–≥–æ —Ç—Ä–∞—Ñ–∏–∫–∞. –í–∞—à–∞ –∑–∞–¥–∞—á–∞ - —Ä–∞–∑—Ä–∞–±–æ—Ç–∞—Ç—å –º–æ–¥–µ–ª—å, –∫–æ—Ç–æ—Ä–∞—è –±—É–¥–µ—Ç –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å —Ç—Ä–∞—Ñ–∏–∫ –Ω–∞ –Ω–æ—Ä–º–∞–ª—å–Ω—ã–π –∏ –∑–ª–æ–Ω–∞–º–µ—Ä–µ–Ω–Ω—ã–π, –≤–∫–ª—é—á–∞—è —Å–ª–µ–¥—É—é—â–∏–µ —Ç–∏–ø—ã –∞—Ç–∞–∫: DDoS, SQL-–∏–Ω—ä–µ–∫—Ü–∏–∏, –±—Ä—É—Ç—Ñ–æ—Ä—Å, –≤—Ä–µ–¥–æ–Ω–æ—Å–Ω—ã–µ –ø—Ä–æ–≥—Ä–∞–º–º—ã –∏ —Ç.–¥.\n",
    "\n",
    "–í —Ö–æ–¥–µ —Ä–∞–±–æ—Ç—ã –≤—ã –ø—Ä–æ–π–¥–µ—Ç–µ –≤—Å–µ –æ—Å–Ω–æ–≤–Ω—ã–µ —ç—Ç–∞–ø—ã –ø–æ–ª–Ω–æ—Ü–µ–Ω–Ω–æ–≥–æ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è:\\\n",
    "üî∏ –∑–∞–≥—Ä—É–∑–∫–∞ –∏ –æ–∑–Ω–∞–∫–æ–º–ª–µ–Ω–∏–µ —Å –¥–∞–Ω–Ω—ã–º–∏,\\\n",
    "üî∏ –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞,\\\n",
    "üî∏ –ø–æ–ª–Ω–æ—Ü–µ–Ω–Ω—ã–π —Ä–∞–∑–≤–µ–¥–æ—á–Ω—ã–π –∞–Ω–∞–ª–∏–∑,\\\n",
    "üî∏ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞ –Ω–æ–≤—ã—Ö —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤,\\\n",
    "üî∏ –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –º—É–ª—å—Ç–∏–∫–æ–ª–ª–∏–Ω–µ–∞—Ä–Ω–æ—Å—Ç—å,\\\n",
    "üî∏ –æ—Ç–±–æ—Ä —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –Ω–∞–±–æ—Ä–∞ –æ–±—É—á–∞—é—â–∏—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤,\\\n",
    "üî∏ –≤—ã–±–æ—Ä –∏ –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π,\\\n",
    "üî∏ –∏—Ç–æ–≥–æ–≤–∞—è –æ—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏,\\\n",
    "üî∏ –∞–Ω–∞–ª–∏–∑ –≤–∞–∂–Ω–æ—Å—Ç–∏ –µ–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤.\n",
    "\n",
    "### –ó–∞–¥–∞—á–∞\n",
    "\n",
    "üî∏ –†–∞–∑—Ä–∞–±–æ—Ç–∞—Ç—å –º–æ–¥–µ–ª—å, –∫–æ—Ç–æ—Ä–∞—è –±—É–¥–µ—Ç –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å —Ç—Ä–∞—Ñ–∏–∫ –Ω–∞ –Ω–æ—Ä–º–∞–ª—å–Ω—ã–π –∏ –∑–ª–æ–Ω–∞–º–µ—Ä–µ–Ω–Ω—ã–π. –ü—Ä–∏ —ç—Ç–æ–º –º–æ–¥–µ–ª—å –¥–æ–ª–∂–Ω–∞ —Ä–∞–±–æ—Ç–∞—Ç—å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ, —Ç–∞–∫ –∫–∞–∫ —Ü–µ–Ω–∞ –æ—à–∏–±–∫–∏ –º–æ–∂–µ—Ç –±—ã—Ç—å –æ—á–µ–Ω—å –≤—ã—Å–æ–∫–∞.\\\n",
    "üî∏ –û—Ü–µ–Ω–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ –º–æ–¥–µ–ª–∏ –ø–æ —Ä–∞–∑–ª–∏—á–Ω—ã–º –º–µ—Ç—Ä–∏–∫–∞–º –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏: precision, recall, f1_score, accuracy.\\\n",
    "üî∏ (*) –î–µ–ø–ª–æ–π: —Ä–∞–∑—Ä–∞–±–æ—Ç–∞—Ç—å REST API —Å–µ—Ä–≤–∏—Å, –∫–æ—Ç–æ—Ä—ã–π –±—É–¥–µ—Ç –ø—Ä–∏–Ω–∏–º–∞—Ç—å –Ω–∞ –≤—Ö–æ–¥ –¥–∞–Ω–Ω—ã–µ —Ç—Ä–∞—Ñ–∏–∫–∞ –∏ –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å –∫–ª–∞—Å—Å —ç—Ç–æ–≥–æ —Ç—Ä–∞—Ñ–∏–∫–∞.\\\n",
    "\n",
    "### –≠—Ç–∞–ø—ã —Ä–∞–±–æ—Ç—ã:\n",
    "\n",
    "üî∏ –í–≤–æ–¥–Ω—ã–π –≤–µ–±–∏–Ω–∞—Ä, –ø–æ—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–¥–∞—á–∏\\\n",
    "üî∏ –°–∞–º–æ—Å—Ç–æ—è—Ç–µ–ª—å–Ω–∞—è —Ä–∞–±–æ—Ç–∞, –ø—Ä–æ–≤–µ–¥–µ–Ω–∏–µ Stand-up, –æ–±—Å—É–∂–¥–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ –∫–∞–Ω–∞–ª–µ\\\n",
    "üî∏ –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø—Ä–æ–µ–∫—Ç–∞\n",
    "\n",
    "### –ò—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ\n",
    "\n",
    "üî∏ –°—Å—ã–ª–∫–∞ –Ω–∞ –¥–∞—Ç–∞—Å–µ—Ç - https://..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ü–ª–∞–Ω —Ä–∞–±–æ—Ç—ã\n",
    "\n",
    "**1. –ó–Ω–∞–∫–æ–º—Å—Ç–≤–æ —Å –¥–∞–Ω–Ω—ã–º–∏**\n",
    "\n",
    "    1.1 –ò–º–ø–æ—Ä—Ç –±–∏–±–ª–∏–æ—Ç–µ–∫\n",
    "    \n",
    "    1.2 –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö\n",
    "    \n",
    "    1.3 –ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö (—Ä–∞–∑–º–µ—Ä, –ø—Ä–∏–∑–Ω–∞–∫–∏, —Å—Ç—Ä–æ–∫–∏, —Ç–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö, –ø—Ä–æ–ø—É—Å–∫–∏, –∞–Ω–æ–º–∞–ª–∏–∏, –¥—É–±–ª–∏–∫–∞—Ç—ã, –∫–æ—Ä–µ–ª—è—Ü–∏—è, —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ)\n",
    "    \n",
    " **2. –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö**\n",
    "    \n",
    "    2.1 –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Ç–∏–ø–æ–≤ –¥–∞–Ω–Ω—ã—Ö \n",
    "    \n",
    "    2.2 –†–∞–∑–±–∏–µ–Ω–∏–µ –Ω–∞ –≤—ã–±–æ—Ä–∫–∏\n",
    "    \n",
    "    2.3 –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∑–Ω–∞—á–µ–Ω–∏–π\n",
    "    \n",
    " **3. –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π**\n",
    " \n",
    " **4. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ñ—É–Ω–∫—Ü–∏–∏ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –≤ —Ñ–∞–π–ª**\n",
    " \n",
    " **5. –í—ã–≤–æ–¥**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –ò–º–ø–æ—Ä—Ç –±–∏–±–ª–∏–æ—Ç–µ–∫ –∏ –∑–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from -r requirements.txt (line 1)) (2.1.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from -r requirements.txt (line 2)) (1.26.0)\n",
      "Requirement already satisfied: ipykernel in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from -r requirements.txt (line 3)) (6.25.2)\n",
      "Requirement already satisfied: scikit_learn in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from -r requirements.txt (line 4)) (1.3.1)\n",
      "Requirement already satisfied: openpyxl in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from -r requirements.txt (line 5)) (3.1.2)\n",
      "Requirement already satisfied: skimpy in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from -r requirements.txt (line 6)) (0.0.11)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from -r requirements.txt (line 7)) (3.8.0)\n",
      "Requirement already satisfied: seaborn in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from -r requirements.txt (line 8)) (0.13.0)\n",
      "Requirement already satisfied: catboost in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from -r requirements.txt (line 9)) (1.2.2)\n",
      "Requirement already satisfied: imblearn in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from -r requirements.txt (line 10)) (0.0)\n",
      "Requirement already satisfied: xgboost in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from -r requirements.txt (line 11)) (2.0.0)\n",
      "Requirement already satisfied: sweetviz in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from -r requirements.txt (line 12)) (2.2.1)\n",
      "Requirement already satisfied: lightgbm in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from -r requirements.txt (line 13)) (4.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from pandas->-r requirements.txt (line 1)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from pandas->-r requirements.txt (line 1)) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from pandas->-r requirements.txt (line 1)) (2023.3)\n",
      "Requirement already satisfied: comm>=0.1.1 in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from ipykernel->-r requirements.txt (line 3)) (0.1.4)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from ipykernel->-r requirements.txt (line 3)) (1.8.0)\n",
      "Requirement already satisfied: ipython>=7.23.1 in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from ipykernel->-r requirements.txt (line 3)) (8.16.1)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from ipykernel->-r requirements.txt (line 3)) (8.3.1)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from ipykernel->-r requirements.txt (line 3)) (5.3.2)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from ipykernel->-r requirements.txt (line 3)) (0.1.6)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from ipykernel->-r requirements.txt (line 3)) (1.5.8)\n",
      "Requirement already satisfied: packaging in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from ipykernel->-r requirements.txt (line 3)) (23.2)\n",
      "Requirement already satisfied: psutil in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from ipykernel->-r requirements.txt (line 3)) (5.9.5)\n",
      "Requirement already satisfied: pyzmq>=20 in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from ipykernel->-r requirements.txt (line 3)) (25.1.1)\n",
      "Requirement already satisfied: tornado>=6.1 in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from ipykernel->-r requirements.txt (line 3)) (6.3.3)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from ipykernel->-r requirements.txt (line 3)) (5.10.1)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from scikit_learn->-r requirements.txt (line 4)) (1.11.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from scikit_learn->-r requirements.txt (line 4)) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from scikit_learn->-r requirements.txt (line 4)) (3.2.0)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from openpyxl->-r requirements.txt (line 5)) (1.1.0)\n",
      "Requirement already satisfied: Pygments<3.0.0,>=2.10.0 in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from skimpy->-r requirements.txt (line 6)) (2.16.1)\n",
      "Requirement already satisfied: click<9.0.0,>=8.1.6 in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from skimpy->-r requirements.txt (line 6)) (8.1.7)\n",
      "Requirement already satisfied: jupyter<2.0.0,>=1.0.0 in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from skimpy->-r requirements.txt (line 6)) (1.0.0)\n",
      "Requirement already satisfied: polars<0.20.0,>=0.19.0 in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from skimpy->-r requirements.txt (line 6)) (0.19.6)\n",
      "Requirement already satisfied: pyarrow<14.0.0,>=13.0.0 in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from skimpy->-r requirements.txt (line 6)) (13.0.0)\n",
      "Requirement already satisfied: rich<14.0,>=10.9 in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from skimpy->-r requirements.txt (line 6)) (13.6.0)\n",
      "Requirement already satisfied: typeguard==4.1.4 in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from skimpy->-r requirements.txt (line 6)) (4.1.4)\n",
      "Requirement already satisfied: typing-extensions>=4.7.0 in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from typeguard==4.1.4->skimpy->-r requirements.txt (line 6)) (4.8.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from matplotlib->-r requirements.txt (line 7)) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from matplotlib->-r requirements.txt (line 7)) (0.12.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from matplotlib->-r requirements.txt (line 7)) (4.43.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from matplotlib->-r requirements.txt (line 7)) (1.4.5)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from matplotlib->-r requirements.txt (line 7)) (10.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from matplotlib->-r requirements.txt (line 7)) (3.1.1)\n",
      "Requirement already satisfied: graphviz in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from catboost->-r requirements.txt (line 9)) (0.20.1)\n",
      "Requirement already satisfied: plotly in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from catboost->-r requirements.txt (line 9)) (5.17.0)\n",
      "Requirement already satisfied: six in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from catboost->-r requirements.txt (line 9)) (1.16.0)\n",
      "Requirement already satisfied: imbalanced-learn in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from imblearn->-r requirements.txt (line 10)) (0.11.0)\n",
      "Requirement already satisfied: tqdm>=4.43.0 in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from sweetviz->-r requirements.txt (line 12)) (4.66.1)\n",
      "Requirement already satisfied: jinja2>=2.11.1 in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from sweetviz->-r requirements.txt (line 12)) (3.1.2)\n",
      "Requirement already satisfied: importlib-resources>=1.2.0 in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from sweetviz->-r requirements.txt (line 12)) (6.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from click<9.0.0,>=8.1.6->skimpy->-r requirements.txt (line 6)) (0.4.6)\n",
      "Requirement already satisfied: backcall in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 3)) (0.2.0)\n",
      "Requirement already satisfied: decorator in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 3)) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 3)) (0.19.1)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 3)) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 3)) (3.0.39)\n",
      "Requirement already satisfied: stack-data in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 3)) (0.6.3)\n",
      "Requirement already satisfied: exceptiongroup in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 3)) (1.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from jinja2>=2.11.1->sweetviz->-r requirements.txt (line 12)) (2.1.3)\n",
      "Requirement already satisfied: notebook in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from jupyter<2.0.0,>=1.0.0->skimpy->-r requirements.txt (line 6)) (7.0.4)\n",
      "Requirement already satisfied: qtconsole in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from jupyter<2.0.0,>=1.0.0->skimpy->-r requirements.txt (line 6)) (5.4.4)\n",
      "Requirement already satisfied: jupyter-console in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from jupyter<2.0.0,>=1.0.0->skimpy->-r requirements.txt (line 6)) (6.6.3)\n",
      "Requirement already satisfied: nbconvert in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from jupyter<2.0.0,>=1.0.0->skimpy->-r requirements.txt (line 6)) (7.8.0)\n",
      "Requirement already satisfied: ipywidgets in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from jupyter<2.0.0,>=1.0.0->skimpy->-r requirements.txt (line 6)) (8.1.1)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->-r requirements.txt (line 3)) (3.10.0)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->-r requirements.txt (line 3)) (306)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from rich<14.0,>=10.9->skimpy->-r requirements.txt (line 6)) (3.0.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from plotly->catboost->-r requirements.txt (line 9)) (8.2.3)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->-r requirements.txt (line 3)) (0.8.3)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich<14.0,>=10.9->skimpy->-r requirements.txt (line 6)) (0.1.2)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=7.23.1->ipykernel->-r requirements.txt (line 3)) (0.2.8)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.9 in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from ipywidgets->jupyter<2.0.0,>=1.0.0->skimpy->-r requirements.txt (line 6)) (4.0.9)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.9 in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from ipywidgets->jupyter<2.0.0,>=1.0.0->skimpy->-r requirements.txt (line 6)) (3.0.9)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from nbconvert->jupyter<2.0.0,>=1.0.0->skimpy->-r requirements.txt (line 6)) (4.12.2)\n",
      "Requirement already satisfied: bleach!=5.0.0 in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from nbconvert->jupyter<2.0.0,>=1.0.0->skimpy->-r requirements.txt (line 6)) (6.0.0)\n",
      "Requirement already satisfied: defusedxml in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from nbconvert->jupyter<2.0.0,>=1.0.0->skimpy->-r requirements.txt (line 6)) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from nbconvert->jupyter<2.0.0,>=1.0.0->skimpy->-r requirements.txt (line 6)) (0.2.2)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from nbconvert->jupyter<2.0.0,>=1.0.0->skimpy->-r requirements.txt (line 6)) (3.0.2)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from nbconvert->jupyter<2.0.0,>=1.0.0->skimpy->-r requirements.txt (line 6)) (0.8.0)\n",
      "Requirement already satisfied: nbformat>=5.7 in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from nbconvert->jupyter<2.0.0,>=1.0.0->skimpy->-r requirements.txt (line 6)) (5.9.2)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from nbconvert->jupyter<2.0.0,>=1.0.0->skimpy->-r requirements.txt (line 6)) (1.5.0)\n",
      "Requirement already satisfied: tinycss2 in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from nbconvert->jupyter<2.0.0,>=1.0.0->skimpy->-r requirements.txt (line 6)) (1.2.1)\n",
      "Requirement already satisfied: jupyter-server<3,>=2.4.0 in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from notebook->jupyter<2.0.0,>=1.0.0->skimpy->-r requirements.txt (line 6)) (2.7.3)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.22.1 in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from notebook->jupyter<2.0.0,>=1.0.0->skimpy->-r requirements.txt (line 6)) (2.25.0)\n",
      "Requirement already satisfied: jupyterlab<5,>=4.0.2 in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from notebook->jupyter<2.0.0,>=1.0.0->skimpy->-r requirements.txt (line 6)) (4.0.6)\n",
      "Requirement already satisfied: notebook-shim<0.3,>=0.2 in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from notebook->jupyter<2.0.0,>=1.0.0->skimpy->-r requirements.txt (line 6)) (0.2.3)\n",
      "Requirement already satisfied: ipython-genutils in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from qtconsole->jupyter<2.0.0,>=1.0.0->skimpy->-r requirements.txt (line 6)) (0.2.0)\n",
      "Requirement already satisfied: qtpy>=2.4.0 in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from qtconsole->jupyter<2.0.0,>=1.0.0->skimpy->-r requirements.txt (line 6)) (2.4.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from stack-data->ipython>=7.23.1->ipykernel->-r requirements.txt (line 3)) (2.0.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from stack-data->ipython>=7.23.1->ipykernel->-r requirements.txt (line 3)) (2.4.0)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from stack-data->ipython>=7.23.1->ipykernel->-r requirements.txt (line 3)) (0.2.2)\n",
      "Requirement already satisfied: webencodings in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from bleach!=5.0.0->nbconvert->jupyter<2.0.0,>=1.0.0->skimpy->-r requirements.txt (line 6)) (0.5.1)\n",
      "Requirement already satisfied: anyio>=3.1.0 in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter<2.0.0,>=1.0.0->skimpy->-r requirements.txt (line 6)) (4.0.0)\n",
      "Requirement already satisfied: argon2-cffi in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter<2.0.0,>=1.0.0->skimpy->-r requirements.txt (line 6)) (23.1.0)\n",
      "Requirement already satisfied: jupyter-events>=0.6.0 in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter<2.0.0,>=1.0.0->skimpy->-r requirements.txt (line 6)) (0.7.0)\n",
      "Requirement already satisfied: jupyter-server-terminals in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter<2.0.0,>=1.0.0->skimpy->-r requirements.txt (line 6)) (0.4.4)\n",
      "Requirement already satisfied: overrides in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter<2.0.0,>=1.0.0->skimpy->-r requirements.txt (line 6)) (7.4.0)\n",
      "Requirement already satisfied: prometheus-client in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter<2.0.0,>=1.0.0->skimpy->-r requirements.txt (line 6)) (0.17.1)\n",
      "Requirement already satisfied: pywinpty in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter<2.0.0,>=1.0.0->skimpy->-r requirements.txt (line 6)) (2.0.11)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter<2.0.0,>=1.0.0->skimpy->-r requirements.txt (line 6)) (1.8.2)\n",
      "Requirement already satisfied: terminado>=0.8.3 in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter<2.0.0,>=1.0.0->skimpy->-r requirements.txt (line 6)) (0.17.1)\n",
      "Requirement already satisfied: websocket-client in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter<2.0.0,>=1.0.0->skimpy->-r requirements.txt (line 6)) (1.6.3)\n",
      "Requirement already satisfied: async-lru>=1.0.0 in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from jupyterlab<5,>=4.0.2->notebook->jupyter<2.0.0,>=1.0.0->skimpy->-r requirements.txt (line 6)) (2.0.4)\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from jupyterlab<5,>=4.0.2->notebook->jupyter<2.0.0,>=1.0.0->skimpy->-r requirements.txt (line 6)) (2.2.0)\n",
      "Requirement already satisfied: tomli in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from jupyterlab<5,>=4.0.2->notebook->jupyter<2.0.0,>=1.0.0->skimpy->-r requirements.txt (line 6)) (2.0.1)\n",
      "Requirement already satisfied: babel>=2.10 in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from jupyterlab-server<3,>=2.22.1->notebook->jupyter<2.0.0,>=1.0.0->skimpy->-r requirements.txt (line 6)) (2.12.1)\n",
      "Requirement already satisfied: json5>=0.9.0 in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from jupyterlab-server<3,>=2.22.1->notebook->jupyter<2.0.0,>=1.0.0->skimpy->-r requirements.txt (line 6)) (0.9.14)\n",
      "Requirement already satisfied: jsonschema>=4.18.0 in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from jupyterlab-server<3,>=2.22.1->notebook->jupyter<2.0.0,>=1.0.0->skimpy->-r requirements.txt (line 6)) (4.19.1)\n",
      "Requirement already satisfied: requests>=2.31 in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from jupyterlab-server<3,>=2.22.1->notebook->jupyter<2.0.0,>=1.0.0->skimpy->-r requirements.txt (line 6)) (2.31.0)\n",
      "Requirement already satisfied: fastjsonschema in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from nbformat>=5.7->nbconvert->jupyter<2.0.0,>=1.0.0->skimpy->-r requirements.txt (line 6)) (2.18.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from beautifulsoup4->nbconvert->jupyter<2.0.0,>=1.0.0->skimpy->-r requirements.txt (line 6)) (2.5)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->notebook->jupyter<2.0.0,>=1.0.0->skimpy->-r requirements.txt (line 6)) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->notebook->jupyter<2.0.0,>=1.0.0->skimpy->-r requirements.txt (line 6)) (1.3.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook->jupyter<2.0.0,>=1.0.0->skimpy->-r requirements.txt (line 6)) (23.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook->jupyter<2.0.0,>=1.0.0->skimpy->-r requirements.txt (line 6)) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook->jupyter<2.0.0,>=1.0.0->skimpy->-r requirements.txt (line 6)) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook->jupyter<2.0.0,>=1.0.0->skimpy->-r requirements.txt (line 6)) (0.10.3)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from jupyter-events>=0.6.0->jupyter-server<3,>=2.4.0->notebook->jupyter<2.0.0,>=1.0.0->skimpy->-r requirements.txt (line 6)) (2.0.7)\n",
      "Requirement already satisfied: pyyaml>=5.3 in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from jupyter-events>=0.6.0->jupyter-server<3,>=2.4.0->notebook->jupyter<2.0.0,>=1.0.0->skimpy->-r requirements.txt (line 6)) (6.0.1)\n",
      "Requirement already satisfied: rfc3339-validator in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from jupyter-events>=0.6.0->jupyter-server<3,>=2.4.0->notebook->jupyter<2.0.0,>=1.0.0->skimpy->-r requirements.txt (line 6)) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from jupyter-events>=0.6.0->jupyter-server<3,>=2.4.0->notebook->jupyter<2.0.0,>=1.0.0->skimpy->-r requirements.txt (line 6)) (0.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from requests>=2.31->jupyterlab-server<3,>=2.22.1->notebook->jupyter<2.0.0,>=1.0.0->skimpy->-r requirements.txt (line 6)) (3.3.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from requests>=2.31->jupyterlab-server<3,>=2.22.1->notebook->jupyter<2.0.0,>=1.0.0->skimpy->-r requirements.txt (line 6)) (2.0.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from requests>=2.31->jupyterlab-server<3,>=2.22.1->notebook->jupyter<2.0.0,>=1.0.0->skimpy->-r requirements.txt (line 6)) (2023.7.22)\n",
      "Requirement already satisfied: argon2-cffi-bindings in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from argon2-cffi->jupyter-server<3,>=2.4.0->notebook->jupyter<2.0.0,>=1.0.0->skimpy->-r requirements.txt (line 6)) (21.2.0)\n",
      "Requirement already satisfied: fqdn in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook->jupyter<2.0.0,>=1.0.0->skimpy->-r requirements.txt (line 6)) (1.5.1)\n",
      "Requirement already satisfied: isoduration in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook->jupyter<2.0.0,>=1.0.0->skimpy->-r requirements.txt (line 6)) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook->jupyter<2.0.0,>=1.0.0->skimpy->-r requirements.txt (line 6)) (2.4)\n",
      "Requirement already satisfied: uri-template in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook->jupyter<2.0.0,>=1.0.0->skimpy->-r requirements.txt (line 6)) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=1.11 in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook->jupyter<2.0.0,>=1.0.0->skimpy->-r requirements.txt (line 6)) (1.13)\n",
      "Requirement already satisfied: cffi>=1.0.1 in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from argon2-cffi-bindings->argon2-cffi->jupyter-server<3,>=2.4.0->notebook->jupyter<2.0.0,>=1.0.0->skimpy->-r requirements.txt (line 6)) (1.16.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->jupyter-server<3,>=2.4.0->notebook->jupyter<2.0.0,>=1.0.0->skimpy->-r requirements.txt (line 6)) (2.21)\n",
      "Requirement already satisfied: arrow>=0.15.0 in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from isoduration->jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook->jupyter<2.0.0,>=1.0.0->skimpy->-r requirements.txt (line 6)) (1.3.0)\n",
      "Requirement already satisfied: types-python-dateutil>=2.8.10 in c:\\users\\user\\documents\\github\\yandex_hackaton_infobez\\.venv\\lib\\site-packages (from arrow>=0.15.0->isoduration->jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook->jupyter<2.0.0,>=1.0.0->skimpy->-r requirements.txt (line 6)) (2.8.19.14)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import warnings\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "from catboost.utils import eval_metric\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.metrics import (accuracy_score, recall_score, precision_score,\n",
    "f1_score, roc_auc_score, roc_curve, confusion_matrix, classification_report, ConfusionMatrixDisplay)\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler, LabelEncoder, OneHotEncoder, RobustScaler, MinMaxScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "# settings for pandas\n",
    "pd.options.display.max_columns = 200\n",
    "pd.options.display.max_rows = 200\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "#pd.options.mode.chained_assignment = None\n",
    "\n",
    "# warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "#warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SIZE = 0.2\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data\\\\network_traffic_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ê–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 539616 entries, 0 to 539615\n",
      "Data columns (total 79 columns):\n",
      " #   Column                        Non-Null Count   Dtype  \n",
      "---  ------                        --------------   -----  \n",
      " 0    Destination Port             539616 non-null  int64  \n",
      " 1    Flow Duration                539616 non-null  int64  \n",
      " 2    Total Fwd Packets            539616 non-null  int64  \n",
      " 3    Total Backward Packets       539616 non-null  int64  \n",
      " 4   Total Length of Fwd Packets   539616 non-null  int64  \n",
      " 5    Total Length of Bwd Packets  539616 non-null  int64  \n",
      " 6    Fwd Packet Length Max        539616 non-null  int64  \n",
      " 7    Fwd Packet Length Min        539616 non-null  int64  \n",
      " 8    Fwd Packet Length Mean       539616 non-null  float64\n",
      " 9    Fwd Packet Length Std        539616 non-null  float64\n",
      " 10  Bwd Packet Length Max         539616 non-null  int64  \n",
      " 11   Bwd Packet Length Min        539616 non-null  int64  \n",
      " 12   Bwd Packet Length Mean       539616 non-null  float64\n",
      " 13   Bwd Packet Length Std        539616 non-null  float64\n",
      " 14  Flow Bytes/s                  539128 non-null  float64\n",
      " 15   Flow Packets/s               539616 non-null  float64\n",
      " 16   Flow IAT Mean                539616 non-null  float64\n",
      " 17   Flow IAT Std                 539616 non-null  float64\n",
      " 18   Flow IAT Max                 539616 non-null  int64  \n",
      " 19   Flow IAT Min                 539616 non-null  int64  \n",
      " 20  Fwd IAT Total                 539616 non-null  int64  \n",
      " 21   Fwd IAT Mean                 539616 non-null  float64\n",
      " 22   Fwd IAT Std                  539616 non-null  float64\n",
      " 23   Fwd IAT Max                  539616 non-null  int64  \n",
      " 24   Fwd IAT Min                  539616 non-null  int64  \n",
      " 25  Bwd IAT Total                 539616 non-null  int64  \n",
      " 26   Bwd IAT Mean                 539616 non-null  float64\n",
      " 27   Bwd IAT Std                  539616 non-null  float64\n",
      " 28   Bwd IAT Max                  539616 non-null  int64  \n",
      " 29   Bwd IAT Min                  539616 non-null  int64  \n",
      " 30  Fwd PSH Flags                 539616 non-null  int64  \n",
      " 31   Bwd PSH Flags                539616 non-null  int64  \n",
      " 32   Fwd URG Flags                539616 non-null  int64  \n",
      " 33   Bwd URG Flags                539616 non-null  int64  \n",
      " 34   Fwd Header Length            539616 non-null  int64  \n",
      " 35   Bwd Header Length            539616 non-null  int64  \n",
      " 36  Fwd Packets/s                 539616 non-null  float64\n",
      " 37   Bwd Packets/s                539616 non-null  float64\n",
      " 38   Min Packet Length            539616 non-null  int64  \n",
      " 39   Max Packet Length            539616 non-null  int64  \n",
      " 40   Packet Length Mean           539616 non-null  float64\n",
      " 41   Packet Length Std            539616 non-null  float64\n",
      " 42   Packet Length Variance       539616 non-null  float64\n",
      " 43  FIN Flag Count                539616 non-null  int64  \n",
      " 44   SYN Flag Count               539616 non-null  int64  \n",
      " 45   RST Flag Count               539616 non-null  int64  \n",
      " 46   PSH Flag Count               539616 non-null  int64  \n",
      " 47   ACK Flag Count               539616 non-null  int64  \n",
      " 48   URG Flag Count               539616 non-null  int64  \n",
      " 49   CWE Flag Count               539616 non-null  int64  \n",
      " 50   ECE Flag Count               539616 non-null  int64  \n",
      " 51   Down/Up Ratio                539616 non-null  int64  \n",
      " 52   Average Packet Size          539616 non-null  float64\n",
      " 53   Avg Fwd Segment Size         539616 non-null  float64\n",
      " 54   Avg Bwd Segment Size         539616 non-null  float64\n",
      " 55   Fwd Header Length.1          539616 non-null  int64  \n",
      " 56  Fwd Avg Bytes/Bulk            539616 non-null  int64  \n",
      " 57   Fwd Avg Packets/Bulk         539616 non-null  int64  \n",
      " 58   Fwd Avg Bulk Rate            539616 non-null  int64  \n",
      " 59   Bwd Avg Bytes/Bulk           539616 non-null  int64  \n",
      " 60   Bwd Avg Packets/Bulk         539616 non-null  int64  \n",
      " 61  Bwd Avg Bulk Rate             539616 non-null  int64  \n",
      " 62  Subflow Fwd Packets           539616 non-null  int64  \n",
      " 63   Subflow Fwd Bytes            539616 non-null  int64  \n",
      " 64   Subflow Bwd Packets          539616 non-null  int64  \n",
      " 65   Subflow Bwd Bytes            539616 non-null  int64  \n",
      " 66  Init_Win_bytes_forward        539616 non-null  int64  \n",
      " 67   Init_Win_bytes_backward      539616 non-null  int64  \n",
      " 68   act_data_pkt_fwd             539616 non-null  int64  \n",
      " 69   min_seg_size_forward         539616 non-null  int64  \n",
      " 70  Active Mean                   539616 non-null  float64\n",
      " 71   Active Std                   539616 non-null  float64\n",
      " 72   Active Max                   539616 non-null  int64  \n",
      " 73   Active Min                   539616 non-null  int64  \n",
      " 74  Idle Mean                     539616 non-null  float64\n",
      " 75   Idle Std                     539616 non-null  float64\n",
      " 76   Idle Max                     539616 non-null  int64  \n",
      " 77   Idle Min                     539616 non-null  int64  \n",
      " 78  Label                         539616 non-null  object \n",
      "dtypes: float64(24), int64(54), object(1)\n",
      "memory usage: 325.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–û–ø–∏—Å–∞–Ω–∏–µ —Å—Ç–æ–ª–±—Ü–æ–≤:**\\\n",
    "`destination_port` - –ü–æ—Ä—Ç –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è —É–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–∞ –∫–æ–Ω–µ—á–Ω—ã–π –ø–æ—Ä—Ç, –∫ –∫–æ—Ç–æ—Ä–æ–º—É –æ—Ç–ø—Ä–∞–≤–ª—è—é—Ç—Å—è –ø–∞–∫–µ—Ç—ã –∏–ª–∏ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ.\\\n",
    "`flow_duration` - –ü—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –ø–æ—Ç–æ–∫–∞ –æ—Ç—Ä–∞–∂–∞–µ—Ç –≤—Ä–µ–º—è –≤ –º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥–∞—Ö, –∫–æ—Ç–æ—Ä–æ–µ –∑–∞—Ç—Ä–∞—Ç–∏–ª–æ—Å—å –Ω–∞ –ø–µ—Ä–µ–¥–∞—á—É –ø–æ—Ç–æ–∫–∞.\\\n",
    "`total_fwd_packets` - –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä—è–º—ã—Ö –ø–∞–∫–µ—Ç–æ–≤ - —ç—Ç–æ —Å—É–º–º–∞ –≤—Å–µ—Ö –ø–∞–∫–µ—Ç–æ–≤, –ø–µ—Ä–µ–¥–∞–≤–∞–µ–º—ã—Ö –≤ –ø—Ä—è–º–æ–º –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–∏.\\\n",
    "`total_backward_packets` - –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞—Ç–Ω—ã—Ö –ø–∞–∫–µ—Ç–æ–≤ - —ç—Ç–æ —Å—É–º–º–∞ –≤—Å–µ—Ö –ø–∞–∫–µ—Ç–æ–≤, –ø–µ—Ä–µ–¥–∞–≤–∞–µ–º—ã—Ö –≤ –æ–±—Ä–∞—Ç–Ω–æ–º –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–∏.\\\n",
    "`total_length_of_fwd_packets` - –û–±—â–∞—è –¥–ª–∏–Ω–∞ –ø—Ä—è–º—ã—Ö –ø–∞–∫–µ—Ç–æ–≤ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –æ–±—â—É—é –¥–ª–∏–Ω—É –≤ –±–∞–π—Ç–∞—Ö –≤—Å–µ—Ö –ø–∞–∫–µ—Ç–æ–≤, –ø–µ—Ä–µ–¥–∞–≤–∞–µ–º—ã—Ö –≤ –ø—Ä—è–º–æ–º –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–∏.\\\n",
    "`total_length_of_bwd_packets` - –û–±—â–∞—è –¥–ª–∏–Ω–∞ –æ–±—Ä–∞—Ç–Ω—ã—Ö –ø–∞–∫–µ—Ç–æ–≤ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –æ–±—â—É—é –¥–ª–∏–Ω—É –≤ –±–∞–π—Ç–∞—Ö –≤—Å–µ—Ö –ø–∞–∫–µ—Ç–æ–≤, –ø–µ—Ä–µ–¥–∞–≤–∞–µ–º—ã—Ö –≤ –æ–±—Ä–∞—Ç–Ω–æ–º –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–∏.\\\n",
    "`fwd_packet_length_max` - –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –ø—Ä—è–º–æ–≥–æ –ø–∞–∫–µ—Ç–∞ - —ç—Ç–æ –Ω–∞–∏–±–æ–ª—å—à–∞—è –¥–ª–∏–Ω–∞ –≤ –±–∞–π—Ç–∞—Ö —Å—Ä–µ–¥–∏ –≤—Å–µ—Ö –ø—Ä—è–º—ã—Ö –ø–∞–∫–µ—Ç–æ–≤.\\\n",
    "`fwd_packet_length_min` - –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –ø—Ä—è–º–æ–≥–æ –ø–∞–∫–µ—Ç–∞ - —ç—Ç–æ –Ω–∞–∏–º–µ–Ω—å—à–∞—è –¥–ª–∏–Ω–∞ –≤ –±–∞–π—Ç–∞—Ö —Å—Ä–µ–¥–∏ –≤—Å–µ—Ö –ø—Ä—è–º—ã—Ö –ø–∞–∫–µ—Ç–æ–≤.\\\n",
    "`fwd_packet_length_mean` - –°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ –ø—Ä—è–º–æ–≥–æ –ø–∞–∫–µ—Ç–∞ - —ç—Ç–æ —Å—Ä–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –¥–ª–∏–Ω –≤ –±–∞–π—Ç–∞—Ö —Å—Ä–µ–¥–∏ –≤—Å–µ—Ö –ø—Ä—è–º—ã—Ö –ø–∞–∫–µ—Ç–æ–≤.\\\n",
    "`fwd_packet_length_std` - –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ –¥–ª–∏–Ω—ã –ø—Ä—è–º–æ–≥–æ –ø–∞–∫–µ—Ç–∞ - —ç—Ç–æ –º–µ—Ä–∞ —Ä–∞–∑–±—Ä–æ—Å–∞ –∑–Ω–∞—á–µ–Ω–∏–π –¥–ª–∏–Ω –ø—Ä—è–º—ã—Ö –ø–∞–∫–µ—Ç–æ–≤ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –∏—Ö —Å—Ä–µ–¥–Ω–µ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è.\\\n",
    "`bwd_packet_length_max` - –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –æ–±—Ä–∞—Ç–Ω–æ–≥–æ –ø–∞–∫–µ—Ç–∞ - —ç—Ç–æ –Ω–∞–∏–±–æ–ª—å—à–∞—è –¥–ª–∏–Ω–∞ –≤ –±–∞–π—Ç–∞—Ö —Å—Ä–µ–¥–∏ –≤—Å–µ—Ö –æ–±—Ä–∞—Ç–Ω—ã—Ö –ø–∞–∫–µ—Ç–æ–≤.\\\n",
    "`bwd_packet_length_min` - –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –æ–±—Ä–∞—Ç–Ω–æ–≥–æ –ø–∞–∫–µ—Ç–∞ - —ç—Ç–æ –Ω–∞–∏–º–µ–Ω—å—à–∞—è –¥–ª–∏–Ω–∞ –≤ –±–∞–π—Ç–∞—Ö —Å—Ä–µ–¥–∏ –≤—Å–µ—Ö –æ–±—Ä–∞—Ç–Ω—ã—Ö –ø–∞–∫–µ—Ç–æ–≤.\\\n",
    "`bwd_packet_length_mean` - –°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ –æ–±—Ä–∞—Ç–Ω–æ–≥–æ –ø–∞–∫–µ—Ç–∞ - —ç—Ç–æ —Å—Ä–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –¥–ª–∏–Ω –≤ –±–∞–π—Ç–∞—Ö —Å—Ä–µ–¥–∏ –≤—Å–µ—Ö –æ–±—Ä–∞—Ç–Ω—ã—Ö –ø–∞–∫–µ—Ç–æ–≤.\\\n",
    "`bwd_packet_length_std` - –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ –¥–ª–∏–Ω –æ–±—Ä–∞—Ç–Ω—ã—Ö –ø–∞–∫–µ—Ç–æ–≤ —É–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–∞ —Ä–∞–∑–±—Ä–æ—Å –∑–Ω–∞—á–µ–Ω–∏–π –¥–ª–∏–Ω –æ–±—Ä–∞—Ç–Ω—ã—Ö –ø–∞–∫–µ—Ç–æ–≤ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –∏—Ö —Å—Ä–µ–¥–Ω–µ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è.\\\n",
    "`flow_bytes/s` - –ë–∞–π—Ç—ã –ø–æ—Ç–æ–∫–∞ –≤ —Å–µ–∫—É–Ω–¥—É –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç —Å–∫–æ–ª—å–∫–æ –±–∞–π—Ç–æ–≤ –ø–µ—Ä–µ–¥–∞–µ—Ç—Å—è –≤ —Å–µ—Ç–∏ –∑–∞ –æ–¥–Ω—É —Å–µ–∫—É–Ω–¥—É.\\\n",
    "`flow_packets/s` - –ü–∞–∫–µ—Ç—ã –ø–æ—Ç–æ–∫–∞ –≤ —Å–µ–∫—É–Ω–¥—É –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç —Å–∫–æ–ª—å–∫–æ –ø–∞–∫–µ—Ç–æ–≤ –ø–µ—Ä–µ–¥–∞–µ—Ç—Å—è –≤ —Å–µ—Ç–∏ –∑–∞ –æ–¥–Ω—É —Å–µ–∫—É–Ω–¥—É.\\\n",
    "`flow_iat_mean` - –°—Ä–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞ –º–µ–∂–¥—É –ø–∞–∫–µ—Ç–∞–º–∏ –ø–æ—Ç–æ–∫–∞ –æ—Ç—Ä–∞–∂–∞–µ—Ç —Å—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è, –∑–∞—Ç—Ä–∞—á–µ–Ω–Ω–æ–µ –Ω–∞ –ø–µ—Ä–µ–¥–∞—á—É –ø–∞–∫–µ—Ç–æ–≤ –ø–æ—Ç–æ–∫–∞.\\\n",
    "`flow_iat_std` - –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞ –º–µ–∂–¥—É –ø–∞–∫–µ—Ç–∞–º–∏ –ø–æ—Ç–æ–∫–∞ —è–≤–ª—è–µ—Ç—Å—è –º–µ—Ä–æ–π —Ä–∞–∑–±—Ä–æ—Å–∞ –∑–Ω–∞—á–µ–Ω–∏–π –∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–≤ –º–µ–∂–¥—É –ø–∞–∫–µ—Ç–∞–º–∏ –ø–æ—Ç–æ–∫–∞ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –∏—Ö —Å—Ä–µ–¥–Ω–µ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è.\\\n",
    "`flow_iat_max` - –ù–∞–∏–±–æ–ª—å—à–∏–π –∏–Ω—Ç–µ—Ä–≤–∞–ª –º–µ–∂–¥—É –ø–∞–∫–µ—Ç–∞–º–∏ –ø–æ—Ç–æ–∫–∞ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è –º–µ–∂–¥—É –ø—Ä–∏–±—ã—Ç–∏–µ–º –ø–∞–∫–µ—Ç–æ–≤ –ø–æ—Ç–æ–∫–∞.\\\n",
    "`flow_iat_min` - –ù–∞–∏–º–µ–Ω—å—à–∏–π –∏–Ω—Ç–µ—Ä–≤–∞–ª –º–µ–∂–¥—É –ø–∞–∫–µ—Ç–∞–º–∏ –ø–æ—Ç–æ–∫–∞ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è –º–µ–∂–¥—É –ø—Ä–∏–±—ã—Ç–∏–µ–º –ø–∞–∫–µ—Ç–æ–≤ –ø–æ—Ç–æ–∫–∞.\\\n",
    "`fwd_iat_total`- –û–±—â–∏–π –∏–Ω—Ç–µ—Ä–≤–∞–ª –º–µ–∂–¥—É –ø—Ä—è–º—ã–º–∏ –ø–∞–∫–µ—Ç–∞–º–∏ –æ–±–æ–∑–Ω–∞—á–∞–µ—Ç —Å—É–º–º–∞—Ä–Ω–æ–µ –≤—Ä–µ–º—è –º–µ–∂–¥—É –æ—Ç–ø—Ä–∞–≤–∫–æ–π –ø—Ä—è–º—ã—Ö –ø–∞–∫–µ—Ç–æ–≤.\\\n",
    "`fwd_iat_mean` - –°—Ä–µ–¥–Ω–∏–π –∏–Ω—Ç–µ—Ä–≤–∞–ª –º–µ–∂–¥—É –ø—Ä—è–º—ã–º–∏ –ø–∞–∫–µ—Ç–∞–º–∏ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Å—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –º–µ–∂–¥—É –æ—Ç–ø—Ä–∞–≤–∫–æ–π –ø—Ä—è–º—ã—Ö –ø–∞–∫–µ—Ç–æ–≤.\\\n",
    "`fwd_iat_std` - –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞ –º–µ–∂–¥—É –ø—Ä—è–º—ã–º–∏ –ø–∞–∫–µ—Ç–∞–º–∏ —è–≤–ª—è–µ—Ç—Å—è –º–µ—Ä–æ–π —Ä–∞–∑–±—Ä–æ—Å–∞ –∑–Ω–∞—á–µ–Ω–∏–π –∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–≤ –º–µ–∂–¥—É –ø—Ä—è–º—ã–º–∏ –ø–∞–∫–µ—Ç–∞–º–∏ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –∏—Ö —Å—Ä–µ–¥–Ω–µ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è.\\\n",
    "`fwd_iat_max` - –ù–∞–∏–±–æ–ª—å—à–∏–π –∏–Ω—Ç–µ—Ä–≤–∞–ª –º–µ–∂–¥—É –ø—Ä—è–º—ã–º–∏ –ø–∞–∫–µ—Ç–∞–º–∏ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è –º–µ–∂–¥—É –æ—Ç–ø—Ä–∞–≤–∫–æ–π –ø—Ä—è–º—ã—Ö –ø–∞–∫–µ—Ç–æ–≤.\\\n",
    "`fwd_iat_min` - –ù–∞–∏–º–µ–Ω—å—à–∏–π –∏–Ω—Ç–µ—Ä–≤–∞–ª –º–µ–∂–¥—É –ø—Ä—è–º—ã–º–∏ –ø–∞–∫–µ—Ç–∞–º–∏ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è –º–µ–∂–¥—É –æ—Ç–ø—Ä–∞–≤–∫–æ–π –ø—Ä—è–º—ã—Ö –ø–∞–∫–µ—Ç–æ–≤.\\\n",
    "`bwd_iat_total` - –û–±—â–∏–π –∏–Ω—Ç–µ—Ä–≤–∞–ª –º–µ–∂–¥—É –æ–±—Ä–∞—Ç–Ω—ã–º–∏ –ø–∞–∫–µ—Ç–∞–º–∏ –æ–±–æ–∑–Ω–∞—á–∞–µ—Ç —Å—É–º–º–∞—Ä–Ω–æ–µ –≤—Ä–µ–º—è –º–µ–∂–¥—É –æ—Ç–ø—Ä–∞–≤–∫–æ–π –æ–±—Ä–∞—Ç–Ω—ã—Ö –ø–∞–∫–µ—Ç–æ–≤.\\\n",
    "`bwd_iat_mean` - –°—Ä–µ–¥–Ω–∏–π –∏–Ω—Ç–µ—Ä–≤–∞–ª –º–µ–∂–¥—É –æ–±—Ä–∞—Ç–Ω—ã–º–∏ –ø–∞–∫–µ—Ç–∞–º–∏ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Å—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –º–µ–∂–¥—É –æ—Ç–ø—Ä–∞–≤–∫–æ–π –æ–±—Ä–∞—Ç–Ω—ã—Ö –ø–∞–∫–µ—Ç–æ–≤.\\\n",
    "`bwd_iat_std` - –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞ –º–µ–∂–¥—É –æ–±—Ä–∞—Ç–Ω—ã–º–∏ –ø–∞–∫–µ—Ç–∞–º–∏ —è–≤–ª—è–µ—Ç—Å—è –º–µ—Ä–æ–π —Ä–∞–∑–±—Ä–æ—Å–∞ –∑–Ω–∞—á–µ–Ω–∏–π –∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–≤ –º–µ–∂–¥—É –æ–±—Ä–∞—Ç–Ω—ã–º–∏ –ø–∞–∫–µ—Ç–∞–º–∏ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –∏—Ö —Å—Ä–µ–¥–Ω–µ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è.\\\n",
    "`bwd_iat_max` - –ù–∞–∏–±–æ–ª—å—à–∏–π –∏–Ω—Ç–µ—Ä–≤–∞–ª –º–µ–∂–¥—É –æ–±—Ä–∞—Ç–Ω—ã–º–∏ –ø–∞–∫–µ—Ç–∞–º–∏ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è –º–µ–∂–¥—É –æ—Ç–ø—Ä–∞–≤–∫–æ–π –æ–±—Ä–∞—Ç–Ω—ã—Ö –ø–∞–∫–µ—Ç–æ–≤.\\\n",
    "`bwd_iat_min` - –ù–∞–∏–º–µ–Ω—å—à–∏–π –∏–Ω—Ç–µ—Ä–≤–∞–ª –º–µ–∂–¥—É –æ–±—Ä–∞—Ç–Ω—ã–º–∏ –ø–∞–∫–µ—Ç–∞–º–∏ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è –º–µ–∂–¥—É –æ—Ç–ø—Ä–∞–≤–∫–æ–π –æ–±—Ä–∞—Ç–Ω—ã—Ö –ø–∞–∫–µ—Ç–æ–≤.\\\n",
    "`fwd_psh_flags` - –§–ª–∞–≥–∏ Push –ø—Ä—è–º—ã—Ö –ø–∞–∫–µ—Ç–æ–≤ –æ–±–æ–∑–Ω–∞—á–∞—é—Ç –ø–∞–∫–µ—Ç—ã, –∫–æ—Ç–æ—Ä—ã–µ —Ç—Ä–µ–±—É—é—Ç –º–æ–º–µ–Ω—Ç–∞–ª—å–Ω–æ–π –ø–µ—Ä–µ–¥–∞—á–∏ –¥–∞–Ω–Ω—ã—Ö –Ω–∞ –ø—Ä–∏–µ–º–Ω—É—é —Å—Ç–æ—Ä–æ–Ω—É –±–µ–∑ –±—É—Ñ–µ—Ä–∏–∑–∞—Ü–∏–∏.\\\n",
    "`bwd_psh_flags` - –§–ª–∞–≥–∏ Push –æ–±—Ä–∞—Ç–Ω—ã—Ö –ø–∞–∫–µ—Ç–æ–≤ –æ–±–æ–∑–Ω–∞—á–∞—é—Ç –ø–∞–∫–µ—Ç—ã, –∫–æ—Ç–æ—Ä—ã–µ —Ç—Ä–µ–±—É—é—Ç –º–æ–º–µ–Ω—Ç–∞–ª—å–Ω–æ–π –ø–µ—Ä–µ–¥–∞—á–∏ –¥–∞–Ω–Ω—ã—Ö –Ω–∞ –æ—Ç–ø—Ä–∞–≤–Ω—É—é —Å—Ç–æ—Ä–æ–Ω—É –±–µ–∑ –±—É—Ñ–µ—Ä–∏–∑–∞—Ü–∏–∏.\\\n",
    "`fwd_urg_flags` - –§–ª–∞–≥–∏ Urgent –ø—Ä—è–º—ã—Ö –ø–∞–∫–µ—Ç–æ–≤ –æ–±–æ–∑–Ω–∞—á–∞—é—Ç –ø–∞–∫–µ—Ç—ã, –∫–æ—Ç–æ—Ä—ã–µ –∏–º–µ—é—Ç –≤—ã—Å–æ–∫–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç –∏ —Ç—Ä–µ–±—É—é—Ç –Ω–µ–º–µ–¥–ª–µ–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏.\\\n",
    "`bwd_urg_flags` - –§–ª–∞–≥–∏ Urgent –æ–±—Ä–∞—Ç–Ω—ã—Ö –ø–∞–∫–µ—Ç–æ–≤ –æ–±–æ–∑–Ω–∞—á–∞—é—Ç –ø–∞–∫–µ—Ç—ã, –∫–æ—Ç–æ—Ä—ã–µ –∏–º–µ—é—Ç –≤—ã—Å–æ–∫–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç –∏ —Ç—Ä–µ–±—É—é—Ç –Ω–µ–º–µ–¥–ª–µ–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏.\\\n",
    "`fwd_header_length` - –î–ª–∏–Ω–∞ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ –ø—Ä—è–º—ã—Ö –ø–∞–∫–µ—Ç–æ–≤ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Ä–∞–∑–º–µ—Ä –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ –ø—Ä—è–º—ã—Ö –ø–∞–∫–µ—Ç–æ–≤ –≤ –±–∞–π—Ç–∞—Ö.\\\n",
    "`bwd_header_length` - –î–ª–∏–Ω–∞ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ –æ–±—Ä–∞—Ç–Ω—ã—Ö –ø–∞–∫–µ—Ç–æ–≤ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Ä–∞–∑–º–µ—Ä –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ –æ–±—Ä–∞—Ç–Ω—ã—Ö –ø–∞–∫–µ—Ç–æ–≤ –≤ –±–∞–π—Ç–∞—Ö.\\\n",
    "`fwd_packets/s` - –ü—Ä—è–º—ã–µ –ø–∞–∫–µ—Ç—ã –≤ —Å–µ–∫—É–Ω–¥—É –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç —Å–∫–æ–ª—å–∫–æ –ø—Ä—è–º—ã—Ö –ø–∞–∫–µ—Ç–æ–≤ –ø–µ—Ä–µ–¥–∞–µ—Ç—Å—è –≤ —Å–µ—Ç–∏ –∑–∞ –æ–¥–Ω—É —Å–µ–∫—É–Ω–¥—É.\\\n",
    "`bwd_packets/s` - –û–±—Ä–∞—Ç–Ω—ã–µ –ø–∞–∫–µ—Ç—ã –≤ —Å–µ–∫—É–Ω–¥—É –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç —Å–∫–æ–ª—å–∫–æ –æ–±—Ä–∞—Ç–Ω—ã—Ö –ø–∞–∫–µ—Ç–æ–≤ –ø–µ—Ä–µ–¥–∞–µ—Ç—Å—è –≤ —Å–µ—Ç–∏ –∑–∞ –æ–¥–Ω—É —Å–µ–∫—É–Ω–¥—É.\\\n",
    "`min_packet_length` - –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –ø–∞–∫–µ—Ç–∞ —É–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–∞ –Ω–∞–∏–º–µ–Ω—å—à—É—é –¥–ª–∏–Ω—É –ø–∞–∫–µ—Ç–∞ –≤ –±–∞–π—Ç–∞—Ö.\\\n",
    "`max_packet_length` - –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –ø–∞–∫–µ—Ç–∞ —É–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–∞ –Ω–∞–∏–±–æ–ª—å—à—É—é –¥–ª–∏–Ω—É –ø–∞–∫–µ—Ç–∞ –≤ –±–∞–π—Ç–∞—Ö.\\\n",
    "`packet_length_mean` - –°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ –ø–∞–∫–µ—Ç–∞ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å–æ–±–æ–π —Å—Ä–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –¥–ª–∏–Ω –≤—Å–µ—Ö –ø–∞–∫–µ—Ç–æ–≤ –≤ –±–∞–π—Ç–∞—Ö.\\\n",
    "`packet_length_std` - –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ –¥–ª–∏–Ω—ã –ø–∞–∫–µ—Ç–∞ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Å—Ç–µ–ø–µ–Ω—å –∏–∑–º–µ–Ω—á–∏–≤–æ—Å—Ç–∏ –¥–ª–∏–Ω –≤—Å–µ—Ö –ø–∞–∫–µ—Ç–æ–≤ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –∏—Ö —Å—Ä–µ–¥–Ω–µ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è.\\\n",
    "`packet_length_variance` - –î–∏—Å–ø–µ—Ä—Å–∏—è –¥–ª–∏–Ω—ã –ø–∞–∫–µ—Ç–∞ —è–≤–ª—è–µ—Ç—Å—è –º–µ—Ä–æ–π —Ä–∞–∑–±—Ä–æ—Å–∞ –∑–Ω–∞—á–µ–Ω–∏–π –¥–ª–∏–Ω –ø–∞–∫–µ—Ç–æ–≤ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –∏—Ö —Å—Ä–µ–¥–Ω–µ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è.\\\n",
    "`fin_flag_count` - –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞–∫–µ—Ç–æ–≤ —Å —Ñ–ª–∞–≥–æ–º FIN —É–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞–∫–µ—Ç–æ–≤, –≤ –∫–æ—Ç–æ—Ä—ã—Ö —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω —Ñ–ª–∞–≥ FIN.\\\n",
    "`syn_flag_count` - –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞–∫–µ—Ç–æ–≤ —Å —Ñ–ª–∞–≥–æ–º SYN —É–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞–∫–µ—Ç–æ–≤, –≤ –∫–æ—Ç–æ—Ä—ã—Ö —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω —Ñ–ª–∞–≥ SYN.\\\n",
    "`rst_flag_count` - –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞–∫–µ—Ç–æ–≤ —Å —Ñ–ª–∞–≥–æ–º RST —É–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞–∫–µ—Ç–æ–≤, –≤ –∫–æ—Ç–æ—Ä—ã—Ö —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω —Ñ–ª–∞–≥ RST.\\\n",
    "`psh_flag_count` - –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞–∫–µ—Ç–æ–≤ —Å —Ñ–ª–∞–≥–æ–º PSH —É–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞–∫–µ—Ç–æ–≤, –≤ –∫–æ—Ç–æ—Ä—ã—Ö —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω —Ñ–ª–∞–≥ PSH.\\\n",
    "`ack_flag_count` - –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞–∫–µ—Ç–æ–≤ —Å —Ñ–ª–∞–≥–æ–º ACK —É–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞–∫–µ—Ç–æ–≤, –≤ –∫–æ—Ç–æ—Ä—ã—Ö —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω —Ñ–ª–∞–≥ ACK.\\\n",
    "`urg_flag_count` - –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞–∫–µ—Ç–æ–≤ —Å —Ñ–ª–∞–≥–æ–º URG —É–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞–∫–µ—Ç–æ–≤, –≤ –∫–æ—Ç–æ—Ä—ã—Ö —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω —Ñ–ª–∞–≥ URG.\\\n",
    "`cwe_flag_count` - –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞–∫–µ—Ç–æ–≤ —Å —Ñ–ª–∞–≥–æ–º CWE —É–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞–∫–µ—Ç–æ–≤, –≤ –∫–æ—Ç–æ—Ä—ã—Ö —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω —Ñ–ª–∞–≥ CWE.\\\n",
    "`ece_flag_count` - –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞–∫–µ—Ç–æ–≤ —Å —Ñ–ª–∞–≥–æ–º ECE —É–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞–∫–µ—Ç–æ–≤, –≤ –∫–æ—Ç–æ—Ä—ã—Ö —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω —Ñ–ª–∞–≥ ECE.\\\n",
    "`down/up_ratio` - –û—Ç–Ω–æ—à–µ–Ω–∏–µ –∑–∞–≥—Ä—É–∑–∫–∏ \"—Å–∫–∞—á–∞—Ç—å/–æ—Ç–ø—Ä–∞–≤–∏—Ç—å\" –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å–æ–±–æ–π —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –ø–∞–∫–µ—Ç–æ–≤ –≤ —Å—Ç–æ—Ä–æ–Ω—É –∑–∞–≥—Ä—É–∑–∫–∏ (—Å–∫–∞—á–∏–≤–∞–Ω–∏—è) –∫ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –ø–∞–∫–µ—Ç–æ–≤ –≤ —Å—Ç–æ—Ä–æ–Ω—É –æ—Ç–ø—Ä–∞–≤–∫–∏.\\\n",
    "`average_packet_size` - –°—Ä–µ–¥–Ω–∏–π —Ä–∞–∑–º–µ—Ä –ø–∞–∫–µ—Ç–∞ —É–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–∞ —Å—Ä–µ–¥–Ω—é—é –¥–ª–∏–Ω—É –ø–∞–∫–µ—Ç–∞ –≤ –±–∞–π—Ç–∞—Ö.\\\n",
    "`avg_fwd_segment_size` - –°—Ä–µ–¥–Ω–∏–π —Ä–∞–∑–º–µ—Ä –ø—Ä—è–º–æ–≥–æ —Å–µ–≥–º–µ–Ω—Ç–∞ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å–æ–±–æ–π —Å—Ä–µ–¥–Ω—é—é –¥–ª–∏–Ω—É –ø—Ä—è–º–æ–≥–æ —Å–µ–≥–º–µ–Ω—Ç–∞ –≤ –±–∞–π—Ç–∞—Ö.\\\n",
    "`avg_bwd_segment_size` - –°—Ä–µ–¥–Ω–∏–π —Ä–∞–∑–º–µ—Ä –æ–±—Ä–∞—Ç–Ω–æ–≥–æ —Å–µ–≥–º–µ–Ω—Ç–∞ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å–æ–±–æ–π —Å—Ä–µ–¥–Ω—é—é –¥–ª–∏–Ω—É –æ–±—Ä–∞—Ç–Ω–æ–≥–æ —Å–µ–≥–º–µ–Ω—Ç–∞ –≤ –±–∞–π—Ç–∞—Ö.\\\n",
    "`fwd_header_length.1` - –î–ª–∏–Ω–∞ –∑–∞–≥–æ–ª–æ–≤–∫–∞ –ø—Ä—è–º–æ–≥–æ –ø–∞–∫–µ—Ç–∞ —É–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–∞ —Ä–∞–∑–º–µ—Ä –∑–∞–≥–æ–ª–æ–≤–∫–∞ –ø—Ä—è–º–æ–≥–æ –ø–∞–∫–µ—Ç–∞ –≤ –±–∞–π—Ç–∞—Ö.\\\n",
    "`fwd_avg_bytes/bulk` - –°—Ä–µ–¥–Ω–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –±–∞–π—Ç –≤ –ø–∞–∫–µ—Ç–µ –ø—Ä—è–º–æ–≥–æ –ø–æ—Ç–æ–∫–∞ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å–æ–±–æ–π —Å—Ä–µ–¥–Ω–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –±–∞–π—Ç –≤ –∫–∞–∂–¥–æ–º –ø–∞–∫–µ—Ç–µ –ø—Ä—è–º–æ–≥–æ –ø–æ—Ç–æ–∫–∞.\\\n",
    "`fwd_avg_packets/bulk` - –°—Ä–µ–¥–Ω–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞–∫–µ—Ç–æ–≤ –≤ –ø—Ä—è–º–æ–º –ø–æ—Ç–æ–∫–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å–æ–±–æ–π —Å—Ä–µ–¥–Ω–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞–∫–µ—Ç–æ–≤ –≤ –∫–∞–∂–¥–æ–º –ø—Ä—è–º–æ–º –ø–æ—Ç–æ–∫–µ.\\\n",
    "`fwd_avg_bulk_rate` - –°—Ä–µ–¥–Ω—è—è —Å–∫–æ—Ä–æ—Å—Ç—å –ø–µ—Ä–µ–¥–∞—á–∏ –±–ª–æ–∫–æ–≤ –≤ –ø—Ä—è–º–æ–º –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–∏ —É–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–∞ —Å—Ä–µ–¥–Ω—é—é —Å–∫–æ—Ä–æ—Å—Ç—å –ø–µ—Ä–µ–¥–∞—á–∏ –±–ª–æ–∫–æ–≤ –¥–∞–Ω–Ω—ã—Ö –≤ –ø—Ä—è–º–æ–º –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–∏.\\\n",
    "`bwd_avg_bytes/bulk` - –°—Ä–µ–¥–Ω–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –±–∞–π—Ç –≤ –±–ª–æ–∫–µ –≤ –æ–±—Ä–∞—Ç–Ω–æ–º –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–∏ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Å—Ä–µ–¥–Ω–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –±–∞–π—Ç–æ–≤ –≤ –∫–∞–∂–¥–æ–º –±–ª–æ–∫–µ –¥–∞–Ω–Ω—ã—Ö –≤ –æ–±—Ä–∞—Ç–Ω–æ–º –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–∏.\\\n",
    "`bwd_avg_packets/bulk` - –°—Ä–µ–¥–Ω–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞–∫–µ—Ç–æ–≤ –≤ –±–ª–æ–∫–µ –≤ –æ–±—Ä–∞—Ç–Ω–æ–º –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–∏ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Å—Ä–µ–¥–Ω–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞–∫–µ—Ç–æ–≤ –≤ –∫–∞–∂–¥–æ–º –±–ª–æ–∫–µ –¥–∞–Ω–Ω—ã—Ö –≤ –æ–±—Ä–∞—Ç–Ω–æ–º –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–∏.\\\n",
    "`bwd_avg_bulk_rate` - –°—Ä–µ–¥–Ω—è—è —Å–∫–æ—Ä–æ—Å—Ç—å –ø–µ—Ä–µ–¥–∞—á–∏ –±–ª–æ–∫–æ–≤ –≤ –æ–±—Ä–∞—Ç–Ω–æ–º –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–∏ —É–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–∞ —Å—Ä–µ–¥–Ω—é—é —Å–∫–æ—Ä–æ—Å—Ç—å –ø–µ—Ä–µ–¥–∞—á–∏ –±–ª–æ–∫–æ–≤ –¥–∞–Ω–Ω—ã—Ö –≤ –æ–±—Ä–∞—Ç–Ω–æ–º –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–∏.\\\n",
    "`subflow_fwd_packets` - –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞–∫–µ—Ç–æ–≤ –≤ –ø–æ–¥–ø–æ—Ç–æ–∫–µ –≤ –ø—Ä—è–º–æ–º –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–∏ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞–∫–µ—Ç–æ–≤, –ø–µ—Ä–µ–¥–∞–≤–∞–µ–º—ã—Ö –≤ –ø–æ–¥–ø–æ—Ç–æ–∫–µ –≤ –ø—Ä—è–º–æ–º –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–∏.\\\n",
    "`subflow_fwd_bytes` - –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –±–∞–π—Ç–æ–≤ –≤ –ø–æ–¥–ø–æ—Ç–æ–∫–µ –≤ –ø—Ä—è–º–æ–º –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–∏ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –±–∞–π—Ç–æ–≤, –ø–µ—Ä–µ–¥–∞–≤–∞–µ–º—ã—Ö –≤ –ø–æ–¥–ø–æ—Ç–æ–∫–µ –≤ –ø—Ä—è–º–æ–º –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–∏.\\\n",
    "`subflow_bwd_packets` - –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞–∫–µ—Ç–æ–≤ –≤ –ø–æ–¥–ø–æ—Ç–æ–∫–µ –≤ –æ–±—Ä–∞—Ç–Ω–æ–º –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–∏ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞–∫–µ—Ç–æ–≤, –ø–µ—Ä–µ–¥–∞–≤–∞–µ–º—ã—Ö –≤ –ø–æ–¥–ø–æ—Ç–æ–∫–µ –≤ –æ–±—Ä–∞—Ç–Ω–æ–º –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–∏.\\\n",
    "`subflow_bwd_bytes` - –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –±–∞–π—Ç–æ–≤ –≤ –ø–æ–¥–ø–æ—Ç–æ–∫–µ –≤ –æ–±—Ä–∞—Ç–Ω–æ–º –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–∏ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –±–∞–π—Ç–æ–≤, –ø–µ—Ä–µ–¥–∞–≤–∞–µ–º—ã—Ö –≤ –ø–æ–¥–ø–æ—Ç–æ–∫–µ –≤ –æ–±—Ä–∞—Ç–Ω–æ–º –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–∏.\\\n",
    "`init_win_bytes_forward` - –ù–∞—á–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –æ–∫–Ω–∞ –ø—Ä–∏–µ–º–∞ –≤ –±–∞–π—Ç–∞—Ö –≤ –ø—Ä—è–º–æ–º –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–∏ —É–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–∞ –Ω–∞—á–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –æ–∫–Ω–∞ –ø—Ä–∏–µ–º–∞ –¥–∞–Ω–Ω—ã—Ö –≤ –±–∞–π—Ç–∞—Ö –≤ –ø—Ä—è–º–æ–º –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–∏.\\\n",
    "`init_win_bytes_backward` - –ù–∞—á–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –æ–∫–Ω–∞ –ø—Ä–∏–µ–º–∞ –≤ –±–∞–π—Ç–∞—Ö –≤ –æ–±—Ä–∞—Ç–Ω–æ–º –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–∏ —É–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–∞ –Ω–∞—á–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –æ–∫–Ω–∞ –ø—Ä–∏–µ–º–∞ –¥–∞–Ω–Ω—ã—Ö –≤ –±–∞–π—Ç–∞—Ö –≤ –æ–±—Ä–∞—Ç–Ω–æ–º –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–∏.\\\n",
    "`act_data_pkt_fwd` - –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∞–∫—Ç–∏–≤–Ω—ã—Ö –ø—Ä—è–º—ã—Ö –ø–∞–∫–µ—Ç–æ–≤ –¥–∞–Ω–Ω—ã—Ö –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∞–∫—Ç–∏–≤–Ω—ã—Ö –ø—Ä—è–º—ã—Ö –ø–∞–∫–µ—Ç–æ–≤ –ø–µ—Ä–µ–¥–∞—á–∏ –¥–∞–Ω–Ω—ã—Ö.\\\n",
    "`min_seg_size_forward` - –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä —Å–µ–≥–º–µ–Ω—Ç–∞ –≤ –ø—Ä—è–º–æ–º –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–∏ —É–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–∞ –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä —Å–µ–≥–º–µ–Ω—Ç–∞ –¥–∞–Ω–Ω—ã—Ö –≤ –ø—Ä—è–º–æ–º –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–∏.\\\n",
    "`active_mean` - –°—Ä–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –∞–∫—Ç–∏–≤–Ω—ã—Ö —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Å—Ä–µ–¥–Ω–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∞–∫—Ç–∏–≤–Ω—ã—Ö —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π –≤ —Å–µ—Ç–∏.\\\n",
    "`active_std` - –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ –∞–∫—Ç–∏–≤–Ω—ã—Ö —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π —É–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–∞ —Å—Ç–µ–ø–µ–Ω—å –∏–∑–º–µ–Ω—á–∏–≤–æ—Å—Ç–∏ –∞–∫—Ç–∏–≤–Ω—ã—Ö —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –∏—Ö —Å—Ä–µ–¥–Ω–µ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è.\\\n",
    "`active_max` - –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∞–∫—Ç–∏–≤–Ω—ã—Ö —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ –∞–∫—Ç–∏–≤–Ω—ã—Ö —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π –≤ —Å–µ—Ç–∏.\\\n",
    "`active_min` - –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∞–∫—Ç–∏–≤–Ω—ã—Ö —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ –∞–∫—Ç–∏–≤–Ω—ã—Ö —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π –≤ —Å–µ—Ç–∏.\\\n",
    "`idle_mean` - –°—Ä–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –ø—Ä–æ—Å—Ç–∞–∏–≤–∞—é—â–∏—Ö —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Å—Ä–µ–¥–Ω–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ—Å—Ç–∞–∏–≤–∞—é—â–∏—Ö —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π –≤ —Å–µ—Ç–∏.\\\n",
    "`idle_std` - –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ –ø—Ä–æ—Å—Ç–∞–∏–≤–∞—é—â–∏—Ö —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π —É–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–∞ —Å—Ç–µ–ø–µ–Ω—å –∏–∑–º–µ–Ω—á–∏–≤–æ—Å—Ç–∏ –ø—Ä–æ—Å—Ç–∞–∏–≤–∞—é—â–∏—Ö —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –∏—Ö —Å—Ä–µ–¥–Ω–µ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è.\\\n",
    "`idle_max` - –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ—Å—Ç–∞–∏–≤–∞—é—â–∏—Ö —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ –ø—Ä–æ—Å—Ç–∞–∏–≤–∞—é—â–∏—Ö —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π –≤ —Å–µ—Ç–∏.\\\n",
    "`idle_min` - –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ—Å—Ç–∞–∏–≤–∞—é—â–∏—Ö —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ –ø—Ä–æ—Å—Ç–∞–∏–≤–∞—é—â–∏—Ö —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π –≤ —Å–µ—Ç–∏."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "79 —Å—Ç–æ–ª–±—Ü–æ–≤ –ø–æ 539616 –∑–Ω–∞—á–µ–Ω–∏–π. –¶–µ–ª–µ–≤–æ–π –ø—Ä–∏–∑–Ω–∞–∫ Label.–Ø–≤–Ω—ã—Ö –ø—Ä–æ–ø—É—Å–∫–æ–≤ –Ω–µ—Ç. –¢–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç –æ–∂–∏–¥–∞–µ–º—ã–º.\n",
    "\n",
    "–í –¥–∞–Ω–Ω—ã—Ö –µ—Å—Ç—å —Å—Ç–æ–ª–±—Ü—ã —Å min max mean std –≤–æ–∑–º–æ–∂–Ω–æ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–∏ –Ω–µ –ø–æ—Ç—Ä–µ–±—É–µ—Ç—Å—è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Destination Port</th>\n",
       "      <th>Flow Duration</th>\n",
       "      <th>Total Fwd Packets</th>\n",
       "      <th>Total Backward Packets</th>\n",
       "      <th>Total Length of Fwd Packets</th>\n",
       "      <th>Total Length of Bwd Packets</th>\n",
       "      <th>Fwd Packet Length Max</th>\n",
       "      <th>Fwd Packet Length Min</th>\n",
       "      <th>Fwd Packet Length Mean</th>\n",
       "      <th>Fwd Packet Length Std</th>\n",
       "      <th>Bwd Packet Length Max</th>\n",
       "      <th>Bwd Packet Length Min</th>\n",
       "      <th>Bwd Packet Length Mean</th>\n",
       "      <th>Bwd Packet Length Std</th>\n",
       "      <th>Flow Bytes/s</th>\n",
       "      <th>Flow Packets/s</th>\n",
       "      <th>Flow IAT Mean</th>\n",
       "      <th>Flow IAT Std</th>\n",
       "      <th>Flow IAT Max</th>\n",
       "      <th>Flow IAT Min</th>\n",
       "      <th>Fwd IAT Total</th>\n",
       "      <th>Fwd IAT Mean</th>\n",
       "      <th>Fwd IAT Std</th>\n",
       "      <th>Fwd IAT Max</th>\n",
       "      <th>Fwd IAT Min</th>\n",
       "      <th>Bwd IAT Total</th>\n",
       "      <th>Bwd IAT Mean</th>\n",
       "      <th>Bwd IAT Std</th>\n",
       "      <th>Bwd IAT Max</th>\n",
       "      <th>Bwd IAT Min</th>\n",
       "      <th>Fwd PSH Flags</th>\n",
       "      <th>Bwd PSH Flags</th>\n",
       "      <th>Fwd URG Flags</th>\n",
       "      <th>Bwd URG Flags</th>\n",
       "      <th>Fwd Header Length</th>\n",
       "      <th>Bwd Header Length</th>\n",
       "      <th>Fwd Packets/s</th>\n",
       "      <th>Bwd Packets/s</th>\n",
       "      <th>Min Packet Length</th>\n",
       "      <th>Max Packet Length</th>\n",
       "      <th>Packet Length Mean</th>\n",
       "      <th>Packet Length Std</th>\n",
       "      <th>Packet Length Variance</th>\n",
       "      <th>FIN Flag Count</th>\n",
       "      <th>SYN Flag Count</th>\n",
       "      <th>RST Flag Count</th>\n",
       "      <th>PSH Flag Count</th>\n",
       "      <th>ACK Flag Count</th>\n",
       "      <th>URG Flag Count</th>\n",
       "      <th>CWE Flag Count</th>\n",
       "      <th>ECE Flag Count</th>\n",
       "      <th>Down/Up Ratio</th>\n",
       "      <th>Average Packet Size</th>\n",
       "      <th>Avg Fwd Segment Size</th>\n",
       "      <th>Avg Bwd Segment Size</th>\n",
       "      <th>Fwd Header Length.1</th>\n",
       "      <th>Fwd Avg Bytes/Bulk</th>\n",
       "      <th>Fwd Avg Packets/Bulk</th>\n",
       "      <th>Fwd Avg Bulk Rate</th>\n",
       "      <th>Bwd Avg Bytes/Bulk</th>\n",
       "      <th>Bwd Avg Packets/Bulk</th>\n",
       "      <th>Bwd Avg Bulk Rate</th>\n",
       "      <th>Subflow Fwd Packets</th>\n",
       "      <th>Subflow Fwd Bytes</th>\n",
       "      <th>Subflow Bwd Packets</th>\n",
       "      <th>Subflow Bwd Bytes</th>\n",
       "      <th>Init_Win_bytes_forward</th>\n",
       "      <th>Init_Win_bytes_backward</th>\n",
       "      <th>act_data_pkt_fwd</th>\n",
       "      <th>min_seg_size_forward</th>\n",
       "      <th>Active Mean</th>\n",
       "      <th>Active Std</th>\n",
       "      <th>Active Max</th>\n",
       "      <th>Active Min</th>\n",
       "      <th>Idle Mean</th>\n",
       "      <th>Idle Std</th>\n",
       "      <th>Idle Max</th>\n",
       "      <th>Idle Min</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80</td>\n",
       "      <td>5480074</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.46</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.19</td>\n",
       "      <td>0.73</td>\n",
       "      <td>1826691.40</td>\n",
       "      <td>3131700.20</td>\n",
       "      <td>5442804</td>\n",
       "      <td>101</td>\n",
       "      <td>5480074</td>\n",
       "      <td>2740037.00</td>\n",
       "      <td>3822289.80</td>\n",
       "      <td>5442804</td>\n",
       "      <td>37270</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>32</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2.40</td>\n",
       "      <td>3.29</td>\n",
       "      <td>10.80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8192</td>\n",
       "      <td>42780</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>443</td>\n",
       "      <td>711977</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>703</td>\n",
       "      <td>3950</td>\n",
       "      <td>267</td>\n",
       "      <td>0</td>\n",
       "      <td>78.10</td>\n",
       "      <td>103.30</td>\n",
       "      <td>1448</td>\n",
       "      <td>0</td>\n",
       "      <td>395.00</td>\n",
       "      <td>587.50</td>\n",
       "      <td>6535.32</td>\n",
       "      <td>26.69</td>\n",
       "      <td>39554.28</td>\n",
       "      <td>50154.62</td>\n",
       "      <td>120501</td>\n",
       "      <td>1</td>\n",
       "      <td>616301</td>\n",
       "      <td>77037.62</td>\n",
       "      <td>72995.98</td>\n",
       "      <td>215614</td>\n",
       "      <td>230</td>\n",
       "      <td>616874</td>\n",
       "      <td>68541.55</td>\n",
       "      <td>71985.97</td>\n",
       "      <td>199836</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>296</td>\n",
       "      <td>328</td>\n",
       "      <td>12.64</td>\n",
       "      <td>14.05</td>\n",
       "      <td>0</td>\n",
       "      <td>1448</td>\n",
       "      <td>232.60</td>\n",
       "      <td>442.80</td>\n",
       "      <td>196012.66</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>244.90</td>\n",
       "      <td>78.10</td>\n",
       "      <td>395.00</td>\n",
       "      <td>296</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>703</td>\n",
       "      <td>10</td>\n",
       "      <td>3950</td>\n",
       "      <td>29200</td>\n",
       "      <td>252</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53</td>\n",
       "      <td>153398</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>224</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "      <td>112.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1981.77</td>\n",
       "      <td>26.08</td>\n",
       "      <td>51132.67</td>\n",
       "      <td>88558.31</td>\n",
       "      <td>153391</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>13.04</td>\n",
       "      <td>13.04</td>\n",
       "      <td>40</td>\n",
       "      <td>112</td>\n",
       "      <td>68.80</td>\n",
       "      <td>39.44</td>\n",
       "      <td>1555.20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>86.00</td>\n",
       "      <td>40.00</td>\n",
       "      <td>112.00</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>2</td>\n",
       "      <td>224</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>57660</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>128</td>\n",
       "      <td>46</td>\n",
       "      <td>46</td>\n",
       "      <td>46.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3017.69</td>\n",
       "      <td>34.69</td>\n",
       "      <td>57660.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>57660</td>\n",
       "      <td>57660</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>17.34</td>\n",
       "      <td>17.34</td>\n",
       "      <td>46</td>\n",
       "      <td>128</td>\n",
       "      <td>73.30</td>\n",
       "      <td>47.34</td>\n",
       "      <td>2241.33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>110.00</td>\n",
       "      <td>46.00</td>\n",
       "      <td>128.00</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8446</td>\n",
       "      <td>767</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>6</td>\n",
       "      <td>31</td>\n",
       "      <td>6</td>\n",
       "      <td>14.34</td>\n",
       "      <td>14.44</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>63885.27</td>\n",
       "      <td>5215.12</td>\n",
       "      <td>255.67</td>\n",
       "      <td>394.29</td>\n",
       "      <td>710</td>\n",
       "      <td>3</td>\n",
       "      <td>713</td>\n",
       "      <td>356.50</td>\n",
       "      <td>499.92</td>\n",
       "      <td>710</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>20</td>\n",
       "      <td>3911.34</td>\n",
       "      <td>1303.78</td>\n",
       "      <td>6</td>\n",
       "      <td>31</td>\n",
       "      <td>11.00</td>\n",
       "      <td>11.18</td>\n",
       "      <td>125.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.75</td>\n",
       "      <td>14.34</td>\n",
       "      <td>6.00</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1017</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Destination Port   Flow Duration   Total Fwd Packets  \\\n",
       "0                 80         5480074                   3   \n",
       "1                443          711977                   9   \n",
       "2                 53          153398                   2   \n",
       "3                 53           57660                   1   \n",
       "4               8446             767                   3   \n",
       "\n",
       "    Total Backward Packets  Total Length of Fwd Packets  \\\n",
       "0                        1                           12   \n",
       "1                       10                          703   \n",
       "2                        2                           80   \n",
       "3                        1                           46   \n",
       "4                        1                           43   \n",
       "\n",
       "    Total Length of Bwd Packets   Fwd Packet Length Max  \\\n",
       "0                             0                       6   \n",
       "1                          3950                     267   \n",
       "2                           224                      40   \n",
       "3                           128                      46   \n",
       "4                             6                      31   \n",
       "\n",
       "    Fwd Packet Length Min   Fwd Packet Length Mean   Fwd Packet Length Std  \\\n",
       "0                       0                     4.00                    3.46   \n",
       "1                       0                    78.10                  103.30   \n",
       "2                      40                    40.00                    0.00   \n",
       "3                      46                    46.00                    0.00   \n",
       "4                       6                    14.34                   14.44   \n",
       "\n",
       "   Bwd Packet Length Max   Bwd Packet Length Min   Bwd Packet Length Mean  \\\n",
       "0                      0                       0                     0.00   \n",
       "1                   1448                       0                   395.00   \n",
       "2                    112                     112                   112.00   \n",
       "3                    128                     128                   128.00   \n",
       "4                      6                       6                     6.00   \n",
       "\n",
       "    Bwd Packet Length Std  Flow Bytes/s   Flow Packets/s   Flow IAT Mean  \\\n",
       "0                    0.00          2.19             0.73      1826691.40   \n",
       "1                  587.50       6535.32            26.69        39554.28   \n",
       "2                    0.00       1981.77            26.08        51132.67   \n",
       "3                    0.00       3017.69            34.69        57660.00   \n",
       "4                    0.00      63885.27          5215.12          255.67   \n",
       "\n",
       "    Flow IAT Std   Flow IAT Max   Flow IAT Min  Fwd IAT Total   Fwd IAT Mean  \\\n",
       "0     3131700.20        5442804            101        5480074     2740037.00   \n",
       "1       50154.62         120501              1         616301       77037.62   \n",
       "2       88558.31         153391              3              3           3.00   \n",
       "3           0.00          57660          57660              0           0.00   \n",
       "4         394.29            710              3            713         356.50   \n",
       "\n",
       "    Fwd IAT Std   Fwd IAT Max   Fwd IAT Min  Bwd IAT Total   Bwd IAT Mean  \\\n",
       "0    3822289.80       5442804         37270              0           0.00   \n",
       "1      72995.98        215614           230         616874       68541.55   \n",
       "2          0.00             3             3              4           4.00   \n",
       "3          0.00             0             0              0           0.00   \n",
       "4        499.92           710             3              0           0.00   \n",
       "\n",
       "    Bwd IAT Std   Bwd IAT Max   Bwd IAT Min  Fwd PSH Flags   Bwd PSH Flags  \\\n",
       "0          0.00             0             0              0               0   \n",
       "1      71985.97        199836             1              0               0   \n",
       "2          0.00             4             4              0               0   \n",
       "3          0.00             0             0              0               0   \n",
       "4          0.00             0             0              0               0   \n",
       "\n",
       "    Fwd URG Flags   Bwd URG Flags   Fwd Header Length   Bwd Header Length  \\\n",
       "0               0               0                  72                  32   \n",
       "1               0               0                 296                 328   \n",
       "2               0               0                  40                  40   \n",
       "3               0               0                  20                  20   \n",
       "4               0               0                  60                  20   \n",
       "\n",
       "   Fwd Packets/s   Bwd Packets/s   Min Packet Length   Max Packet Length  \\\n",
       "0           0.55            0.18                   0                   6   \n",
       "1          12.64           14.05                   0                1448   \n",
       "2          13.04           13.04                  40                 112   \n",
       "3          17.34           17.34                  46                 128   \n",
       "4        3911.34         1303.78                   6                  31   \n",
       "\n",
       "    Packet Length Mean   Packet Length Std   Packet Length Variance  \\\n",
       "0                 2.40                3.29                    10.80   \n",
       "1               232.60              442.80                196012.66   \n",
       "2                68.80               39.44                  1555.20   \n",
       "3                73.30               47.34                  2241.33   \n",
       "4                11.00               11.18                   125.00   \n",
       "\n",
       "   FIN Flag Count   SYN Flag Count   RST Flag Count   PSH Flag Count  \\\n",
       "0               0                0                0                1   \n",
       "1               0                0                0                1   \n",
       "2               0                0                0                0   \n",
       "3               0                0                0                0   \n",
       "4               0                0                0                0   \n",
       "\n",
       "    ACK Flag Count   URG Flag Count   CWE Flag Count   ECE Flag Count  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                1                0                0                0   \n",
       "\n",
       "    Down/Up Ratio   Average Packet Size   Avg Fwd Segment Size  \\\n",
       "0               0                  3.00                   4.00   \n",
       "1               1                244.90                  78.10   \n",
       "2               1                 86.00                  40.00   \n",
       "3               1                110.00                  46.00   \n",
       "4               0                 13.75                  14.34   \n",
       "\n",
       "    Avg Bwd Segment Size   Fwd Header Length.1  Fwd Avg Bytes/Bulk  \\\n",
       "0                   0.00                    72                   0   \n",
       "1                 395.00                   296                   0   \n",
       "2                 112.00                    40                   0   \n",
       "3                 128.00                    20                   0   \n",
       "4                   6.00                    60                   0   \n",
       "\n",
       "    Fwd Avg Packets/Bulk   Fwd Avg Bulk Rate   Bwd Avg Bytes/Bulk  \\\n",
       "0                      0                   0                    0   \n",
       "1                      0                   0                    0   \n",
       "2                      0                   0                    0   \n",
       "3                      0                   0                    0   \n",
       "4                      0                   0                    0   \n",
       "\n",
       "    Bwd Avg Packets/Bulk  Bwd Avg Bulk Rate  Subflow Fwd Packets  \\\n",
       "0                      0                  0                    3   \n",
       "1                      0                  0                    9   \n",
       "2                      0                  0                    2   \n",
       "3                      0                  0                    1   \n",
       "4                      0                  0                    3   \n",
       "\n",
       "    Subflow Fwd Bytes   Subflow Bwd Packets   Subflow Bwd Bytes  \\\n",
       "0                  12                     1                   0   \n",
       "1                 703                    10                3950   \n",
       "2                  80                     2                 224   \n",
       "3                  46                     1                 128   \n",
       "4                  43                     1                   6   \n",
       "\n",
       "   Init_Win_bytes_forward   Init_Win_bytes_backward   act_data_pkt_fwd  \\\n",
       "0                    8192                     42780                  2   \n",
       "1                   29200                       252                  4   \n",
       "2                      -1                        -1                  1   \n",
       "3                      -1                        -1                  0   \n",
       "4                    1017                         0                  2   \n",
       "\n",
       "    min_seg_size_forward  Active Mean   Active Std   Active Max   Active Min  \\\n",
       "0                     20         0.00         0.00            0            0   \n",
       "1                     32         0.00         0.00            0            0   \n",
       "2                     20         0.00         0.00            0            0   \n",
       "3                     20         0.00         0.00            0            0   \n",
       "4                     20         0.00         0.00            0            0   \n",
       "\n",
       "   Idle Mean   Idle Std   Idle Max   Idle Min   Label  \n",
       "0       0.00       0.00          0          0  BENIGN  \n",
       "1       0.00       0.00          0          0  BENIGN  \n",
       "2       0.00       0.00          0          0  BENIGN  \n",
       "3       0.00       0.00          0          0  BENIGN  \n",
       "4       0.00       0.00          0          0  BENIGN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Destination Port</th>\n",
       "      <th>Flow Duration</th>\n",
       "      <th>Total Fwd Packets</th>\n",
       "      <th>Total Backward Packets</th>\n",
       "      <th>Total Length of Fwd Packets</th>\n",
       "      <th>Total Length of Bwd Packets</th>\n",
       "      <th>Fwd Packet Length Max</th>\n",
       "      <th>Fwd Packet Length Min</th>\n",
       "      <th>Fwd Packet Length Mean</th>\n",
       "      <th>Fwd Packet Length Std</th>\n",
       "      <th>Bwd Packet Length Max</th>\n",
       "      <th>Bwd Packet Length Min</th>\n",
       "      <th>Bwd Packet Length Mean</th>\n",
       "      <th>Bwd Packet Length Std</th>\n",
       "      <th>Flow Bytes/s</th>\n",
       "      <th>Flow Packets/s</th>\n",
       "      <th>Flow IAT Mean</th>\n",
       "      <th>Flow IAT Std</th>\n",
       "      <th>Flow IAT Max</th>\n",
       "      <th>Flow IAT Min</th>\n",
       "      <th>Fwd IAT Total</th>\n",
       "      <th>Fwd IAT Mean</th>\n",
       "      <th>Fwd IAT Std</th>\n",
       "      <th>Fwd IAT Max</th>\n",
       "      <th>Fwd IAT Min</th>\n",
       "      <th>Bwd IAT Total</th>\n",
       "      <th>Bwd IAT Mean</th>\n",
       "      <th>Bwd IAT Std</th>\n",
       "      <th>Bwd IAT Max</th>\n",
       "      <th>Bwd IAT Min</th>\n",
       "      <th>Fwd PSH Flags</th>\n",
       "      <th>Bwd PSH Flags</th>\n",
       "      <th>Fwd URG Flags</th>\n",
       "      <th>Bwd URG Flags</th>\n",
       "      <th>Fwd Header Length</th>\n",
       "      <th>Bwd Header Length</th>\n",
       "      <th>Fwd Packets/s</th>\n",
       "      <th>Bwd Packets/s</th>\n",
       "      <th>Min Packet Length</th>\n",
       "      <th>Max Packet Length</th>\n",
       "      <th>Packet Length Mean</th>\n",
       "      <th>Packet Length Std</th>\n",
       "      <th>Packet Length Variance</th>\n",
       "      <th>FIN Flag Count</th>\n",
       "      <th>SYN Flag Count</th>\n",
       "      <th>RST Flag Count</th>\n",
       "      <th>PSH Flag Count</th>\n",
       "      <th>ACK Flag Count</th>\n",
       "      <th>URG Flag Count</th>\n",
       "      <th>CWE Flag Count</th>\n",
       "      <th>ECE Flag Count</th>\n",
       "      <th>Down/Up Ratio</th>\n",
       "      <th>Average Packet Size</th>\n",
       "      <th>Avg Fwd Segment Size</th>\n",
       "      <th>Avg Bwd Segment Size</th>\n",
       "      <th>Fwd Header Length.1</th>\n",
       "      <th>Fwd Avg Bytes/Bulk</th>\n",
       "      <th>Fwd Avg Packets/Bulk</th>\n",
       "      <th>Fwd Avg Bulk Rate</th>\n",
       "      <th>Bwd Avg Bytes/Bulk</th>\n",
       "      <th>Bwd Avg Packets/Bulk</th>\n",
       "      <th>Bwd Avg Bulk Rate</th>\n",
       "      <th>Subflow Fwd Packets</th>\n",
       "      <th>Subflow Fwd Bytes</th>\n",
       "      <th>Subflow Bwd Packets</th>\n",
       "      <th>Subflow Bwd Bytes</th>\n",
       "      <th>Init_Win_bytes_forward</th>\n",
       "      <th>Init_Win_bytes_backward</th>\n",
       "      <th>act_data_pkt_fwd</th>\n",
       "      <th>min_seg_size_forward</th>\n",
       "      <th>Active Mean</th>\n",
       "      <th>Active Std</th>\n",
       "      <th>Active Max</th>\n",
       "      <th>Active Min</th>\n",
       "      <th>Idle Mean</th>\n",
       "      <th>Idle Std</th>\n",
       "      <th>Idle Max</th>\n",
       "      <th>Idle Min</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>539616.00</td>\n",
       "      <td>539616.00</td>\n",
       "      <td>539616.00</td>\n",
       "      <td>539616.00</td>\n",
       "      <td>539616.00</td>\n",
       "      <td>539616.00</td>\n",
       "      <td>539616.00</td>\n",
       "      <td>539616.00</td>\n",
       "      <td>539616.00</td>\n",
       "      <td>539616.00</td>\n",
       "      <td>539616.00</td>\n",
       "      <td>539616.00</td>\n",
       "      <td>539616.00</td>\n",
       "      <td>539616.00</td>\n",
       "      <td>539128.00</td>\n",
       "      <td>539616.00</td>\n",
       "      <td>539616.00</td>\n",
       "      <td>539616.00</td>\n",
       "      <td>539616.00</td>\n",
       "      <td>539616.00</td>\n",
       "      <td>539616.00</td>\n",
       "      <td>539616.00</td>\n",
       "      <td>539616.00</td>\n",
       "      <td>539616.00</td>\n",
       "      <td>539616.00</td>\n",
       "      <td>539616.00</td>\n",
       "      <td>539616.00</td>\n",
       "      <td>539616.00</td>\n",
       "      <td>539616.00</td>\n",
       "      <td>539616.00</td>\n",
       "      <td>539616.00</td>\n",
       "      <td>539616.00</td>\n",
       "      <td>539616.00</td>\n",
       "      <td>539616.00</td>\n",
       "      <td>539616.00</td>\n",
       "      <td>539616.00</td>\n",
       "      <td>539616.00</td>\n",
       "      <td>539616.00</td>\n",
       "      <td>539616.00</td>\n",
       "      <td>539616.00</td>\n",
       "      <td>539616.00</td>\n",
       "      <td>539616.00</td>\n",
       "      <td>539616.00</td>\n",
       "      <td>539616.00</td>\n",
       "      <td>539616.00</td>\n",
       "      <td>539616.00</td>\n",
       "      <td>539616.00</td>\n",
       "      <td>539616.00</td>\n",
       "      <td>539616.00</td>\n",
       "      <td>539616.00</td>\n",
       "      <td>539616.00</td>\n",
       "      <td>539616.00</td>\n",
       "      <td>539616.00</td>\n",
       "      <td>539616.00</td>\n",
       "      <td>539616.00</td>\n",
       "      <td>539616.00</td>\n",
       "      <td>539616.00</td>\n",
       "      <td>539616.00</td>\n",
       "      <td>539616.00</td>\n",
       "      <td>539616.00</td>\n",
       "      <td>539616.00</td>\n",
       "      <td>539616.00</td>\n",
       "      <td>539616.00</td>\n",
       "      <td>539616.00</td>\n",
       "      <td>539616.00</td>\n",
       "      <td>539616.00</td>\n",
       "      <td>539616.00</td>\n",
       "      <td>539616.00</td>\n",
       "      <td>539616.00</td>\n",
       "      <td>539616.00</td>\n",
       "      <td>539616.00</td>\n",
       "      <td>539616.00</td>\n",
       "      <td>539616.00</td>\n",
       "      <td>539616.00</td>\n",
       "      <td>539616.00</td>\n",
       "      <td>539616.00</td>\n",
       "      <td>539616.00</td>\n",
       "      <td>539616.00</td>\n",
       "      <td>539616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>240000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5563.06</td>\n",
       "      <td>21066929.37</td>\n",
       "      <td>6.12</td>\n",
       "      <td>5.99</td>\n",
       "      <td>408.24</td>\n",
       "      <td>7999.78</td>\n",
       "      <td>169.45</td>\n",
       "      <td>11.86</td>\n",
       "      <td>44.68</td>\n",
       "      <td>59.53</td>\n",
       "      <td>1675.07</td>\n",
       "      <td>23.51</td>\n",
       "      <td>550.04</td>\n",
       "      <td>697.31</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>2134902.45</td>\n",
       "      <td>5264534.55</td>\n",
       "      <td>17318403.50</td>\n",
       "      <td>294558.36</td>\n",
       "      <td>20756340.18</td>\n",
       "      <td>4036797.30</td>\n",
       "      <td>6666492.26</td>\n",
       "      <td>17200410.93</td>\n",
       "      <td>1035760.29</td>\n",
       "      <td>9601754.01</td>\n",
       "      <td>2028745.22</td>\n",
       "      <td>2413091.18</td>\n",
       "      <td>6464188.15</td>\n",
       "      <td>814778.83</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-4593.96</td>\n",
       "      <td>-4290.45</td>\n",
       "      <td>71421.49</td>\n",
       "      <td>7885.31</td>\n",
       "      <td>9.61</td>\n",
       "      <td>1723.70</td>\n",
       "      <td>276.58</td>\n",
       "      <td>544.09</td>\n",
       "      <td>1112687.62</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>305.36</td>\n",
       "      <td>44.68</td>\n",
       "      <td>550.04</td>\n",
       "      <td>-4593.96</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.12</td>\n",
       "      <td>408.24</td>\n",
       "      <td>5.99</td>\n",
       "      <td>7998.77</td>\n",
       "      <td>7564.76</td>\n",
       "      <td>1277.94</td>\n",
       "      <td>2.95</td>\n",
       "      <td>-2429.31</td>\n",
       "      <td>115498.42</td>\n",
       "      <td>40375.70</td>\n",
       "      <td>167288.24</td>\n",
       "      <td>89830.17</td>\n",
       "      <td>16101546.63</td>\n",
       "      <td>958564.89</td>\n",
       "      <td>16872266.93</td>\n",
       "      <td>15391495.53</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>14921.26</td>\n",
       "      <td>38121719.63</td>\n",
       "      <td>345.11</td>\n",
       "      <td>463.49</td>\n",
       "      <td>7478.35</td>\n",
       "      <td>1014441.80</td>\n",
       "      <td>560.53</td>\n",
       "      <td>60.96</td>\n",
       "      <td>150.87</td>\n",
       "      <td>217.73</td>\n",
       "      <td>2843.53</td>\n",
       "      <td>55.20</td>\n",
       "      <td>869.70</td>\n",
       "      <td>1255.31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5824584.75</td>\n",
       "      <td>10551103.82</td>\n",
       "      <td>33957014.03</td>\n",
       "      <td>4269410.12</td>\n",
       "      <td>38121061.80</td>\n",
       "      <td>10627587.74</td>\n",
       "      <td>13914086.55</td>\n",
       "      <td>34021535.79</td>\n",
       "      <td>8949950.83</td>\n",
       "      <td>28072181.79</td>\n",
       "      <td>9045625.35</td>\n",
       "      <td>8975672.92</td>\n",
       "      <td>21921965.46</td>\n",
       "      <td>7698886.82</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2095355.38</td>\n",
       "      <td>2076610.16</td>\n",
       "      <td>268528.74</td>\n",
       "      <td>38472.68</td>\n",
       "      <td>21.55</td>\n",
       "      <td>2862.90</td>\n",
       "      <td>416.17</td>\n",
       "      <td>903.66</td>\n",
       "      <td>2468133.75</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.63</td>\n",
       "      <td>457.15</td>\n",
       "      <td>150.87</td>\n",
       "      <td>869.70</td>\n",
       "      <td>2095355.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>345.11</td>\n",
       "      <td>7478.35</td>\n",
       "      <td>463.49</td>\n",
       "      <td>1013814.39</td>\n",
       "      <td>13440.65</td>\n",
       "      <td>6590.25</td>\n",
       "      <td>267.51</td>\n",
       "      <td>1052328.64</td>\n",
       "      <td>778752.95</td>\n",
       "      <td>434703.20</td>\n",
       "      <td>1059625.81</td>\n",
       "      <td>709971.01</td>\n",
       "      <td>33154633.35</td>\n",
       "      <td>6461275.27</td>\n",
       "      <td>34038514.45</td>\n",
       "      <td>32956945.19</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00</td>\n",
       "      <td>-12.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-12000000.00</td>\n",
       "      <td>-2000000.00</td>\n",
       "      <td>-12.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-12.00</td>\n",
       "      <td>-13.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-12.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-1073741320.00</td>\n",
       "      <td>-1073741320.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-1073741320.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-536870660.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>80.00</td>\n",
       "      <td>73.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>102.04</td>\n",
       "      <td>0.73</td>\n",
       "      <td>59.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>71.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>40.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>3.33</td>\n",
       "      <td>2.19</td>\n",
       "      <td>4.80</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>40.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>80.00</td>\n",
       "      <td>49739.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>44.00</td>\n",
       "      <td>105.00</td>\n",
       "      <td>23.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11.22</td>\n",
       "      <td>0.00</td>\n",
       "      <td>60.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>54.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2263.83</td>\n",
       "      <td>81.92</td>\n",
       "      <td>17000.58</td>\n",
       "      <td>10944.70</td>\n",
       "      <td>42572.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>482.00</td>\n",
       "      <td>271.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>439.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>64.00</td>\n",
       "      <td>40.00</td>\n",
       "      <td>40.92</td>\n",
       "      <td>4.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>71.00</td>\n",
       "      <td>50.80</td>\n",
       "      <td>18.86</td>\n",
       "      <td>355.95</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>64.50</td>\n",
       "      <td>11.22</td>\n",
       "      <td>54.00</td>\n",
       "      <td>64.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>44.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>105.00</td>\n",
       "      <td>274.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>24.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>443.00</td>\n",
       "      <td>10640295.25</td>\n",
       "      <td>6.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>320.00</td>\n",
       "      <td>8216.25</td>\n",
       "      <td>272.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>48.56</td>\n",
       "      <td>91.70</td>\n",
       "      <td>2796.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>824.50</td>\n",
       "      <td>835.50</td>\n",
       "      <td>125000.00</td>\n",
       "      <td>28985.51</td>\n",
       "      <td>1734360.65</td>\n",
       "      <td>3073641.88</td>\n",
       "      <td>8020226.50</td>\n",
       "      <td>54.00</td>\n",
       "      <td>8699965.50</td>\n",
       "      <td>2153087.25</td>\n",
       "      <td>2907944.03</td>\n",
       "      <td>7341524.00</td>\n",
       "      <td>49.00</td>\n",
       "      <td>151874.25</td>\n",
       "      <td>33099.85</td>\n",
       "      <td>58444.52</td>\n",
       "      <td>136467.50</td>\n",
       "      <td>46.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>164.00</td>\n",
       "      <td>136.00</td>\n",
       "      <td>14705.88</td>\n",
       "      <td>8695.65</td>\n",
       "      <td>6.00</td>\n",
       "      <td>2896.00</td>\n",
       "      <td>484.57</td>\n",
       "      <td>812.50</td>\n",
       "      <td>659877.56</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>523.00</td>\n",
       "      <td>48.56</td>\n",
       "      <td>824.50</td>\n",
       "      <td>164.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>320.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>8216.25</td>\n",
       "      <td>8192.00</td>\n",
       "      <td>235.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>32.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>7125040.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7143036.50</td>\n",
       "      <td>6028677.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>65533.00</td>\n",
       "      <td>119999993.00</td>\n",
       "      <td>200755.00</td>\n",
       "      <td>270686.00</td>\n",
       "      <td>2866110.00</td>\n",
       "      <td>591000000.00</td>\n",
       "      <td>24820.00</td>\n",
       "      <td>2065.00</td>\n",
       "      <td>5940.00</td>\n",
       "      <td>7050.00</td>\n",
       "      <td>17376.00</td>\n",
       "      <td>2042.00</td>\n",
       "      <td>5800.00</td>\n",
       "      <td>8190.00</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>120000000.00</td>\n",
       "      <td>84700000.00</td>\n",
       "      <td>120000000.00</td>\n",
       "      <td>120000000.00</td>\n",
       "      <td>120000000.00</td>\n",
       "      <td>120000000.00</td>\n",
       "      <td>83200000.00</td>\n",
       "      <td>120000000.00</td>\n",
       "      <td>120000000.00</td>\n",
       "      <td>120000000.00</td>\n",
       "      <td>120000000.00</td>\n",
       "      <td>81700000.00</td>\n",
       "      <td>120000000.00</td>\n",
       "      <td>120000000.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4173072.00</td>\n",
       "      <td>5413720.00</td>\n",
       "      <td>3000000.00</td>\n",
       "      <td>2000000.00</td>\n",
       "      <td>1330.00</td>\n",
       "      <td>24820.00</td>\n",
       "      <td>2160.00</td>\n",
       "      <td>4732.00</td>\n",
       "      <td>22400000.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>29.00</td>\n",
       "      <td>2508.00</td>\n",
       "      <td>5940.00</td>\n",
       "      <td>5800.00</td>\n",
       "      <td>4173072.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>200755.00</td>\n",
       "      <td>2866110.00</td>\n",
       "      <td>270686.00</td>\n",
       "      <td>590596141.00</td>\n",
       "      <td>65535.00</td>\n",
       "      <td>65535.00</td>\n",
       "      <td>192491.00</td>\n",
       "      <td>138.00</td>\n",
       "      <td>102000000.00</td>\n",
       "      <td>63500000.00</td>\n",
       "      <td>102000000.00</td>\n",
       "      <td>102000000.00</td>\n",
       "      <td>120000000.00</td>\n",
       "      <td>76900000.00</td>\n",
       "      <td>120000000.00</td>\n",
       "      <td>120000000.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Destination Port   Flow Duration   Total Fwd Packets  \\\n",
       "count           539616.00       539616.00           539616.00   \n",
       "unique                NaN             NaN                 NaN   \n",
       "top                   NaN             NaN                 NaN   \n",
       "freq                  NaN             NaN                 NaN   \n",
       "mean              5563.06     21066929.37                6.12   \n",
       "std              14921.26     38121719.63              345.11   \n",
       "min                  0.00          -12.00                1.00   \n",
       "25%                 80.00           73.00                1.00   \n",
       "50%                 80.00        49739.00                2.00   \n",
       "75%                443.00     10640295.25                6.00   \n",
       "max              65533.00    119999993.00           200755.00   \n",
       "\n",
       "         Total Backward Packets  Total Length of Fwd Packets  \\\n",
       "count                 539616.00                    539616.00   \n",
       "unique                      NaN                          NaN   \n",
       "top                         NaN                          NaN   \n",
       "freq                        NaN                          NaN   \n",
       "mean                       5.99                       408.24   \n",
       "std                      463.49                      7478.35   \n",
       "min                        0.00                         0.00   \n",
       "25%                        1.00                         2.00   \n",
       "50%                        2.00                        44.00   \n",
       "75%                        5.00                       320.00   \n",
       "max                   270686.00                   2866110.00   \n",
       "\n",
       "         Total Length of Bwd Packets   Fwd Packet Length Max  \\\n",
       "count                      539616.00               539616.00   \n",
       "unique                           NaN                     NaN   \n",
       "top                              NaN                     NaN   \n",
       "freq                             NaN                     NaN   \n",
       "mean                         7999.78                  169.45   \n",
       "std                       1014441.80                  560.53   \n",
       "min                             0.00                    0.00   \n",
       "25%                             0.00                    2.00   \n",
       "50%                           105.00                   23.00   \n",
       "75%                          8216.25                  272.00   \n",
       "max                     591000000.00                24820.00   \n",
       "\n",
       "         Fwd Packet Length Min   Fwd Packet Length Mean  \\\n",
       "count                539616.00                539616.00   \n",
       "unique                     NaN                      NaN   \n",
       "top                        NaN                      NaN   \n",
       "freq                       NaN                      NaN   \n",
       "mean                     11.86                    44.68   \n",
       "std                      60.96                   150.87   \n",
       "min                       0.00                     0.00   \n",
       "25%                       0.00                     2.00   \n",
       "50%                       0.00                    11.22   \n",
       "75%                       6.00                    48.56   \n",
       "max                    2065.00                  5940.00   \n",
       "\n",
       "         Fwd Packet Length Std  Bwd Packet Length Max   Bwd Packet Length Min  \\\n",
       "count                539616.00              539616.00               539616.00   \n",
       "unique                     NaN                    NaN                     NaN   \n",
       "top                        NaN                    NaN                     NaN   \n",
       "freq                       NaN                    NaN                     NaN   \n",
       "mean                     59.53                1675.07                   23.51   \n",
       "std                     217.73                2843.53                   55.20   \n",
       "min                       0.00                   0.00                    0.00   \n",
       "25%                       0.00                   0.00                    0.00   \n",
       "50%                       0.00                  60.00                    0.00   \n",
       "75%                      91.70                2796.00                    6.00   \n",
       "max                    7050.00               17376.00                 2042.00   \n",
       "\n",
       "         Bwd Packet Length Mean   Bwd Packet Length Std  Flow Bytes/s  \\\n",
       "count                 539616.00               539616.00     539128.00   \n",
       "unique                      NaN                     NaN           NaN   \n",
       "top                         NaN                     NaN           NaN   \n",
       "freq                        NaN                     NaN           NaN   \n",
       "mean                     550.04                  697.31           inf   \n",
       "std                      869.70                 1255.31           NaN   \n",
       "min                        0.00                    0.00  -12000000.00   \n",
       "25%                        0.00                    0.00        102.04   \n",
       "50%                       54.00                    0.00       2263.83   \n",
       "75%                      824.50                  835.50     125000.00   \n",
       "max                     5800.00                 8190.00           inf   \n",
       "\n",
       "         Flow Packets/s   Flow IAT Mean   Flow IAT Std   Flow IAT Max  \\\n",
       "count         539616.00       539616.00      539616.00      539616.00   \n",
       "unique              NaN             NaN            NaN            NaN   \n",
       "top                 NaN             NaN            NaN            NaN   \n",
       "freq                NaN             NaN            NaN            NaN   \n",
       "mean                inf      2134902.45     5264534.55    17318403.50   \n",
       "std                 NaN      5824584.75    10551103.82    33957014.03   \n",
       "min         -2000000.00          -12.00           0.00         -12.00   \n",
       "25%                0.73           59.00           0.00          71.00   \n",
       "50%               81.92        17000.58       10944.70       42572.00   \n",
       "75%            28985.51      1734360.65     3073641.88     8020226.50   \n",
       "max                 inf    120000000.00    84700000.00   120000000.00   \n",
       "\n",
       "         Flow IAT Min  Fwd IAT Total   Fwd IAT Mean   Fwd IAT Std  \\\n",
       "count       539616.00      539616.00      539616.00     539616.00   \n",
       "unique            NaN            NaN            NaN           NaN   \n",
       "top               NaN            NaN            NaN           NaN   \n",
       "freq              NaN            NaN            NaN           NaN   \n",
       "mean        294558.36    20756340.18     4036797.30    6666492.26   \n",
       "std        4269410.12    38121061.80    10627587.74   13914086.55   \n",
       "min            -13.00           0.00           0.00          0.00   \n",
       "25%              3.00           0.00           0.00          0.00   \n",
       "50%              5.00         482.00         271.00          0.00   \n",
       "75%             54.00     8699965.50     2153087.25    2907944.03   \n",
       "max      120000000.00   120000000.00   120000000.00   83200000.00   \n",
       "\n",
       "         Fwd IAT Max   Fwd IAT Min  Bwd IAT Total   Bwd IAT Mean  \\\n",
       "count      539616.00     539616.00      539616.00      539616.00   \n",
       "unique           NaN           NaN            NaN            NaN   \n",
       "top              NaN           NaN            NaN            NaN   \n",
       "freq             NaN           NaN            NaN            NaN   \n",
       "mean     17200410.93    1035760.29     9601754.01     2028745.22   \n",
       "std      34021535.79    8949950.83    28072181.79     9045625.35   \n",
       "min             0.00        -12.00           0.00           0.00   \n",
       "25%             0.00          0.00           0.00           0.00   \n",
       "50%           439.00          3.00           3.00           3.00   \n",
       "75%       7341524.00         49.00      151874.25       33099.85   \n",
       "max     120000000.00  120000000.00   120000000.00   120000000.00   \n",
       "\n",
       "         Bwd IAT Std   Bwd IAT Max   Bwd IAT Min  Fwd PSH Flags  \\\n",
       "count      539616.00     539616.00     539616.00      539616.00   \n",
       "unique           NaN           NaN           NaN            NaN   \n",
       "top              NaN           NaN           NaN            NaN   \n",
       "freq             NaN           NaN           NaN            NaN   \n",
       "mean      2413091.18    6464188.15     814778.83           0.04   \n",
       "std       8975672.92   21921965.46    7698886.82           0.19   \n",
       "min             0.00          0.00          0.00           0.00   \n",
       "25%             0.00          0.00          0.00           0.00   \n",
       "50%             0.00          3.00          1.00           0.00   \n",
       "75%         58444.52     136467.50         46.00           0.00   \n",
       "max      81700000.00  120000000.00  120000000.00           1.00   \n",
       "\n",
       "         Bwd PSH Flags   Fwd URG Flags   Bwd URG Flags   Fwd Header Length  \\\n",
       "count        539616.00       539616.00       539616.00           539616.00   \n",
       "unique             NaN             NaN             NaN                 NaN   \n",
       "top                NaN             NaN             NaN                 NaN   \n",
       "freq               NaN             NaN             NaN                 NaN   \n",
       "mean              0.00            0.00            0.00            -4593.96   \n",
       "std               0.00            0.01            0.00          2095355.38   \n",
       "min               0.00            0.00            0.00      -1073741320.00   \n",
       "25%               0.00            0.00            0.00               40.00   \n",
       "50%               0.00            0.00            0.00               64.00   \n",
       "75%               0.00            0.00            0.00              164.00   \n",
       "max               0.00            1.00            0.00          4173072.00   \n",
       "\n",
       "         Bwd Header Length  Fwd Packets/s   Bwd Packets/s   Min Packet Length  \\\n",
       "count            539616.00      539616.00       539616.00           539616.00   \n",
       "unique                 NaN            NaN             NaN                 NaN   \n",
       "top                    NaN            NaN             NaN                 NaN   \n",
       "freq                   NaN            NaN             NaN                 NaN   \n",
       "mean              -4290.45       71421.49         7885.31                9.61   \n",
       "std             2076610.16      268528.74        38472.68               21.55   \n",
       "min         -1073741320.00           0.00            0.00                0.00   \n",
       "25%                  20.00           0.53            0.06                0.00   \n",
       "50%                  40.00          40.92            4.99                0.00   \n",
       "75%                 136.00       14705.88         8695.65                6.00   \n",
       "max             5413720.00     3000000.00      2000000.00             1330.00   \n",
       "\n",
       "         Max Packet Length   Packet Length Mean   Packet Length Std  \\\n",
       "count            539616.00            539616.00           539616.00   \n",
       "unique                 NaN                  NaN                 NaN   \n",
       "top                    NaN                  NaN                 NaN   \n",
       "freq                   NaN                  NaN                 NaN   \n",
       "mean               1723.70               276.58              544.09   \n",
       "std                2862.90               416.17              903.66   \n",
       "min                   0.00                 0.00                0.00   \n",
       "25%                   6.00                 3.33                2.19   \n",
       "50%                  71.00                50.80               18.86   \n",
       "75%                2896.00               484.57              812.50   \n",
       "max               24820.00              2160.00             4732.00   \n",
       "\n",
       "         Packet Length Variance  FIN Flag Count   SYN Flag Count  \\\n",
       "count                 539616.00       539616.00        539616.00   \n",
       "unique                      NaN             NaN              NaN   \n",
       "top                         NaN             NaN              NaN   \n",
       "freq                        NaN             NaN              NaN   \n",
       "mean                 1112687.62            0.06             0.04   \n",
       "std                  2468133.75            0.24             0.19   \n",
       "min                        0.00            0.00             0.00   \n",
       "25%                        4.80            0.00             0.00   \n",
       "50%                      355.95            0.00             0.00   \n",
       "75%                   659877.56            0.00             0.00   \n",
       "max                 22400000.00            1.00             1.00   \n",
       "\n",
       "         RST Flag Count   PSH Flag Count   ACK Flag Count   URG Flag Count  \\\n",
       "count         539616.00        539616.00        539616.00        539616.00   \n",
       "unique              NaN              NaN              NaN              NaN   \n",
       "top                 NaN              NaN              NaN              NaN   \n",
       "freq                NaN              NaN              NaN              NaN   \n",
       "mean               0.00             0.38             0.37             0.06   \n",
       "std                0.01             0.48             0.48             0.24   \n",
       "min                0.00             0.00             0.00             0.00   \n",
       "25%                0.00             0.00             0.00             0.00   \n",
       "50%                0.00             0.00             0.00             0.00   \n",
       "75%                0.00             1.00             1.00             0.00   \n",
       "max                1.00             1.00             1.00             1.00   \n",
       "\n",
       "         CWE Flag Count   ECE Flag Count   Down/Up Ratio  \\\n",
       "count         539616.00        539616.00       539616.00   \n",
       "unique              NaN              NaN             NaN   \n",
       "top                 NaN              NaN             NaN   \n",
       "freq                NaN              NaN             NaN   \n",
       "mean               0.00             0.00            0.64   \n",
       "std                0.01             0.01            0.63   \n",
       "min                0.00             0.00            0.00   \n",
       "25%                0.00             0.00            0.00   \n",
       "50%                0.00             0.00            1.00   \n",
       "75%                0.00             0.00            1.00   \n",
       "max                1.00             1.00           29.00   \n",
       "\n",
       "         Average Packet Size   Avg Fwd Segment Size   Avg Bwd Segment Size  \\\n",
       "count              539616.00              539616.00              539616.00   \n",
       "unique                   NaN                    NaN                    NaN   \n",
       "top                      NaN                    NaN                    NaN   \n",
       "freq                     NaN                    NaN                    NaN   \n",
       "mean                  305.36                  44.68                 550.04   \n",
       "std                   457.15                 150.87                 869.70   \n",
       "min                     0.00                   0.00                   0.00   \n",
       "25%                     5.00                   2.00                   0.00   \n",
       "50%                    64.50                  11.22                  54.00   \n",
       "75%                   523.00                  48.56                 824.50   \n",
       "max                  2508.00                5940.00                5800.00   \n",
       "\n",
       "         Fwd Header Length.1  Fwd Avg Bytes/Bulk   Fwd Avg Packets/Bulk  \\\n",
       "count              539616.00           539616.00              539616.00   \n",
       "unique                   NaN                 NaN                    NaN   \n",
       "top                      NaN                 NaN                    NaN   \n",
       "freq                     NaN                 NaN                    NaN   \n",
       "mean                -4593.96                0.00                   0.00   \n",
       "std               2095355.38                0.00                   0.00   \n",
       "min           -1073741320.00                0.00                   0.00   \n",
       "25%                    40.00                0.00                   0.00   \n",
       "50%                    64.00                0.00                   0.00   \n",
       "75%                   164.00                0.00                   0.00   \n",
       "max               4173072.00                0.00                   0.00   \n",
       "\n",
       "         Fwd Avg Bulk Rate   Bwd Avg Bytes/Bulk   Bwd Avg Packets/Bulk  \\\n",
       "count            539616.00            539616.00              539616.00   \n",
       "unique                 NaN                  NaN                    NaN   \n",
       "top                    NaN                  NaN                    NaN   \n",
       "freq                   NaN                  NaN                    NaN   \n",
       "mean                  0.00                 0.00                   0.00   \n",
       "std                   0.00                 0.00                   0.00   \n",
       "min                   0.00                 0.00                   0.00   \n",
       "25%                   0.00                 0.00                   0.00   \n",
       "50%                   0.00                 0.00                   0.00   \n",
       "75%                   0.00                 0.00                   0.00   \n",
       "max                   0.00                 0.00                   0.00   \n",
       "\n",
       "        Bwd Avg Bulk Rate  Subflow Fwd Packets   Subflow Fwd Bytes  \\\n",
       "count           539616.00            539616.00           539616.00   \n",
       "unique                NaN                  NaN                 NaN   \n",
       "top                   NaN                  NaN                 NaN   \n",
       "freq                  NaN                  NaN                 NaN   \n",
       "mean                 0.00                 6.12              408.24   \n",
       "std                  0.00               345.11             7478.35   \n",
       "min                  0.00                 1.00                0.00   \n",
       "25%                  0.00                 1.00                2.00   \n",
       "50%                  0.00                 2.00               44.00   \n",
       "75%                  0.00                 6.00              320.00   \n",
       "max                  0.00            200755.00          2866110.00   \n",
       "\n",
       "         Subflow Bwd Packets   Subflow Bwd Bytes  Init_Win_bytes_forward  \\\n",
       "count              539616.00           539616.00               539616.00   \n",
       "unique                   NaN                 NaN                     NaN   \n",
       "top                      NaN                 NaN                     NaN   \n",
       "freq                     NaN                 NaN                     NaN   \n",
       "mean                    5.99             7998.77                 7564.76   \n",
       "std                   463.49          1013814.39                13440.65   \n",
       "min                     0.00                0.00                   -1.00   \n",
       "25%                     1.00                0.00                    0.00   \n",
       "50%                     2.00              105.00                  274.00   \n",
       "75%                     5.00             8216.25                 8192.00   \n",
       "max                270686.00        590596141.00                65535.00   \n",
       "\n",
       "         Init_Win_bytes_backward   act_data_pkt_fwd   min_seg_size_forward  \\\n",
       "count                  539616.00          539616.00              539616.00   \n",
       "unique                       NaN                NaN                    NaN   \n",
       "top                          NaN                NaN                    NaN   \n",
       "freq                         NaN                NaN                    NaN   \n",
       "mean                     1277.94               2.95               -2429.31   \n",
       "std                      6590.25             267.51             1052328.64   \n",
       "min                        -1.00               0.00          -536870660.00   \n",
       "25%                        -1.00               0.00                  20.00   \n",
       "50%                         0.00               1.00                  24.00   \n",
       "75%                       235.00               2.00                  32.00   \n",
       "max                     65535.00          192491.00                 138.00   \n",
       "\n",
       "        Active Mean   Active Std   Active Max   Active Min    Idle Mean  \\\n",
       "count     539616.00    539616.00    539616.00    539616.00    539616.00   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean      115498.42     40375.70    167288.24     89830.17  16101546.63   \n",
       "std       778752.95    434703.20   1059625.81    709971.01  33154633.35   \n",
       "min            0.00         0.00         0.00         0.00         0.00   \n",
       "25%            0.00         0.00         0.00         0.00         0.00   \n",
       "50%            0.00         0.00         0.00         0.00         0.00   \n",
       "75%            6.00         0.00         6.00         5.00   7125040.75   \n",
       "max    102000000.00  63500000.00 102000000.00 102000000.00 120000000.00   \n",
       "\n",
       "          Idle Std     Idle Max     Idle Min   Label  \n",
       "count    539616.00    539616.00    539616.00  539616  \n",
       "unique         NaN          NaN          NaN      15  \n",
       "top            NaN          NaN          NaN  BENIGN  \n",
       "freq           NaN          NaN          NaN  240000  \n",
       "mean     958564.89  16872266.93  15391495.53     NaN  \n",
       "std     6461275.27  34038514.45  32956945.19     NaN  \n",
       "min           0.00         0.00         0.00     NaN  \n",
       "25%           0.00         0.00         0.00     NaN  \n",
       "50%           0.00         0.00         0.00     NaN  \n",
       "75%           0.00   7143036.50   6028677.00     NaN  \n",
       "max    76900000.00 120000000.00 120000000.00     NaN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([' Destination Port', ' Flow Duration', ' Total Fwd Packets',\n",
       "       ' Total Backward Packets', 'Total Length of Fwd Packets',\n",
       "       ' Total Length of Bwd Packets', ' Fwd Packet Length Max',\n",
       "       ' Fwd Packet Length Min', ' Fwd Packet Length Mean',\n",
       "       ' Fwd Packet Length Std', 'Bwd Packet Length Max',\n",
       "       ' Bwd Packet Length Min', ' Bwd Packet Length Mean',\n",
       "       ' Bwd Packet Length Std', 'Flow Bytes/s', ' Flow Packets/s',\n",
       "       ' Flow IAT Mean', ' Flow IAT Std', ' Flow IAT Max', ' Flow IAT Min',\n",
       "       'Fwd IAT Total', ' Fwd IAT Mean', ' Fwd IAT Std', ' Fwd IAT Max',\n",
       "       ' Fwd IAT Min', 'Bwd IAT Total', ' Bwd IAT Mean', ' Bwd IAT Std',\n",
       "       ' Bwd IAT Max', ' Bwd IAT Min', 'Fwd PSH Flags', ' Bwd PSH Flags',\n",
       "       ' Fwd URG Flags', ' Bwd URG Flags', ' Fwd Header Length',\n",
       "       ' Bwd Header Length', 'Fwd Packets/s', ' Bwd Packets/s',\n",
       "       ' Min Packet Length', ' Max Packet Length', ' Packet Length Mean',\n",
       "       ' Packet Length Std', ' Packet Length Variance', 'FIN Flag Count',\n",
       "       ' SYN Flag Count', ' RST Flag Count', ' PSH Flag Count',\n",
       "       ' ACK Flag Count', ' URG Flag Count', ' CWE Flag Count',\n",
       "       ' ECE Flag Count', ' Down/Up Ratio', ' Average Packet Size',\n",
       "       ' Avg Fwd Segment Size', ' Avg Bwd Segment Size',\n",
       "       ' Fwd Header Length.1', 'Fwd Avg Bytes/Bulk', ' Fwd Avg Packets/Bulk',\n",
       "       ' Fwd Avg Bulk Rate', ' Bwd Avg Bytes/Bulk', ' Bwd Avg Packets/Bulk',\n",
       "       'Bwd Avg Bulk Rate', 'Subflow Fwd Packets', ' Subflow Fwd Bytes',\n",
       "       ' Subflow Bwd Packets', ' Subflow Bwd Bytes', 'Init_Win_bytes_forward',\n",
       "       ' Init_Win_bytes_backward', ' act_data_pkt_fwd',\n",
       "       ' min_seg_size_forward', 'Active Mean', ' Active Std', ' Active Max',\n",
       "       ' Active Min', 'Idle Mean', ' Idle Std', ' Idle Max', ' Idle Min',\n",
       "       'Label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ï—Å—Ç—å –∑–Ω–∞—á–µ–Ω–∏—è inf –∑–∞–º–µ–Ω–∏–º –∏—Ö"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_col_names = []\n",
    "for column in df.columns:\n",
    "    new_col_names.append(column.strip().replace(' ', '_').lower())\n",
    "\n",
    "df.columns = new_col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['destination_port', 'flow_duration', 'total_fwd_packets',\n",
       "       'total_backward_packets', 'total_length_of_fwd_packets',\n",
       "       'total_length_of_bwd_packets', 'fwd_packet_length_max',\n",
       "       'fwd_packet_length_min', 'fwd_packet_length_mean',\n",
       "       'fwd_packet_length_std', 'bwd_packet_length_max',\n",
       "       'bwd_packet_length_min', 'bwd_packet_length_mean',\n",
       "       'bwd_packet_length_std', 'flow_bytes/s', 'flow_packets/s',\n",
       "       'flow_iat_mean', 'flow_iat_std', 'flow_iat_max', 'flow_iat_min',\n",
       "       'fwd_iat_total', 'fwd_iat_mean', 'fwd_iat_std', 'fwd_iat_max',\n",
       "       'fwd_iat_min', 'bwd_iat_total', 'bwd_iat_mean', 'bwd_iat_std',\n",
       "       'bwd_iat_max', 'bwd_iat_min', 'fwd_psh_flags', 'bwd_psh_flags',\n",
       "       'fwd_urg_flags', 'bwd_urg_flags', 'fwd_header_length',\n",
       "       'bwd_header_length', 'fwd_packets/s', 'bwd_packets/s',\n",
       "       'min_packet_length', 'max_packet_length', 'packet_length_mean',\n",
       "       'packet_length_std', 'packet_length_variance', 'fin_flag_count',\n",
       "       'syn_flag_count', 'rst_flag_count', 'psh_flag_count', 'ack_flag_count',\n",
       "       'urg_flag_count', 'cwe_flag_count', 'ece_flag_count', 'down/up_ratio',\n",
       "       'average_packet_size', 'avg_fwd_segment_size', 'avg_bwd_segment_size',\n",
       "       'fwd_header_length.1', 'fwd_avg_bytes/bulk', 'fwd_avg_packets/bulk',\n",
       "       'fwd_avg_bulk_rate', 'bwd_avg_bytes/bulk', 'bwd_avg_packets/bulk',\n",
       "       'bwd_avg_bulk_rate', 'subflow_fwd_packets', 'subflow_fwd_bytes',\n",
       "       'subflow_bwd_packets', 'subflow_bwd_bytes', 'init_win_bytes_forward',\n",
       "       'init_win_bytes_backward', 'act_data_pkt_fwd', 'min_seg_size_forward',\n",
       "       'active_mean', 'active_std', 'active_max', 'active_min', 'idle_mean',\n",
       "       'idle_std', 'idle_max', 'idle_min', 'label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü—Ä–æ–≤–µ—Ä–∏–º –Ω–∞ –¥—É–±–ª–∏–∫–∞—Ç—ã –∏ —É–¥–∞–ª–∏–º –∏—Ö"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–î–æ (539616, 79)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: 64601\n",
      "–ü–æ—Å–ª–µ: (475015, 79)\n"
     ]
    }
   ],
   "source": [
    "print(f'–î–æ {df.shape}')\n",
    "print(f'–û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {df.duplicated().sum()}')\n",
    "df = df.drop_duplicates()\n",
    "print(f'–ü–æ—Å–ª–µ: {df.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–£–¥–∞–ª–∏–º —Å—Ç–æ–ª–±—Ü—ã —Å –æ–¥–∏–Ω–∫–æ–≤—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–î–æ: (475015, 79)\n",
      "–ü–æ—Å–ª–µ: (475015, 71)\n"
     ]
    }
   ],
   "source": [
    "print(f'–î–æ: {df.shape}')\n",
    "# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –≤—Å–µ —Å—Ç–æ–ª–±—Ü—ã –Ω–∞ –Ω–∞–ª–∏—á–∏–µ –æ–¥–∏–Ω–∞–∫–æ–≤—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π\n",
    "for column in df.columns:\n",
    "    if df[column].drop_duplicates().shape[0] == 1:\n",
    "        df = df.drop(column, axis=1)\n",
    "print(f'–ü–æ—Å–ª–µ: {df.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EDA –ø—Ä–æ–≤–µ–¥–µ–º —Å –ø–æ–º–æ—â—å—é –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ SweetViz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#report = sv.analyze(df)\n",
    "#report.show_html('common analysis.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## destination_port"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü–æ—Ä—Ç –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è - –ø–æ—Ä—Ç –Ω–∞ –∫–æ—Ç–æ—Ä—ã–π –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç—Å—è –ø–∞–∫–µ—Ç. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count   475015.00\n",
       "mean      5871.02\n",
       "std      15516.41\n",
       "min          0.00\n",
       "25%         80.00\n",
       "50%         80.00\n",
       "75%        443.00\n",
       "max      65533.00\n",
       "Name: destination_port, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['destination_port'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–û—Ñ–∏—Ü–∏–∞–ª—å–Ω–æ –ø–æ—Ä—Ç 0 –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, –∏ –∫ –Ω–µ–º—É –Ω–µ–ª—å–∑—è –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è. –û–¥–Ω–∞–∫–æ –º–æ–∂–Ω–æ –æ—Ç–ø—Ä–∞–≤–ª—è—Ç—å –∏–Ω—Ç–µ—Ä–Ω–µ—Ç-–ø–∞–∫–µ—Ç –Ω–∞ –ø–æ—Ä—Ç 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "destination_port\n",
       "80      198897\n",
       "53       99170\n",
       "443      50896\n",
       "21        6517\n",
       "22        4342\n",
       "123       2390\n",
       "8080      1455\n",
       "389        715\n",
       "88         603\n",
       "465        417\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['destination_port'].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{118, 1313, 3359, 6062, 174833}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(df.query('label != \"BENIGN\"')['destination_port'].value_counts().head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–û–±—ã—á–Ω—ã–µ –ø–æ—Ä—Ç—ã –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ –≤ —Å–µ—Ç—è—Ö. –í–æ–∑–º–æ–∂–Ω–æ —á–∞—Å—Ç–æ—Ç–∞ –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö –∏–Ω—Ç—É–∏—Ç–≤–Ω–æ –Ω–µ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å —Ç–∞–∫–æ–π –≤—ã—Å–æ–∫–æ–π, –Ω–æ –Ω–∞–∑–Ω–∞—á–µ–Ω–∏–µ —Å–µ—Ç–∏ –º—ã –Ω–µ –∑–Ω–∞–µ–º."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ò–∑ —Ç–æ–ø –ø–æ—Ä—Ç–æ–≤ –¥–ª—è –∞—Ç–∞–∫ –≤—ã–ø–∞–¥–∞–µ—Ç 53 –ø–æ—Ä—Ç, –∑–∞—Ä–µ–∑–µ—Ä–≤–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Å DNS-—Å–µ—Ä–≤–µ—Ä–∞–º–∏. –¢–∞–∫–∂–µ –≤ —Ç–æ–ø –ø–æ–ø–∞–¥–∞—é—Ç —Å–ª–µ–¥—É—é—â–∏–µ –ø–æ—Ä—Ç—ã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{139, 444, 445, 587, 6779}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(df.query('label != \"BENIGN\"')['destination_port'].value_counts().head(10).index) - \\\n",
    "set(df['destination_port'].value_counts().head(10).index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "23 - Telnet (–ø—Ä–æ—Ç–æ–∫–æ–ª —É–¥–∞–ª–µ–Ω–Ω–æ–≥–æ —Ç–µ—Ä–º–∏–Ω–∞–ª–∞)\\\n",
    "139 - –ü–æ—Ä—Ç 139 –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –æ–±—â–µ–≥–æ –¥–æ—Å—Ç—É–ø–∞ –∫ —Ñ–∞–π–ª–∞–º –∏ –ø—Ä–∏–Ω—Ç–µ—Ä–∞–º, —ç—Ç–æ –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω—ã–π –Ω–∞–∏–±–æ–ª–µ–µ –æ–ø–∞—Å–Ω—ã–π –ø–æ—Ä—Ç –ø–æ—Ç–æ–º—É, —á—Ç–æ –æ—Å—Ç–∞–≤–ª—è–µ—Ç –∂–µ—Å—Ç–∫–∏–π –¥–∏—Å–∫ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –Ω–µ–∑–∞—â–∏—â–µ–Ω–Ω—ã–º\\\n",
    "444 - SNMP –ø—Ä–æ—Ç–æ–∫–æ–ª –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞–º–∏ –≤ IP-—Å–µ—Ç—è—Ö(–º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ç–æ—Ä—ã, –∫–æ–º–º—É—Ç–∞—Ç–æ—Ä—ã, —Å–µ—Ä–≤–µ—Ä—ã, —Ä–∞–±–æ—á–∏–µ —Å—Ç–∞–Ω—Ü–∏–∏, –ø—Ä–∏–Ω—Ç–µ—Ä—ã, –º–æ–¥–µ–º–Ω—ã–µ —Å—Ç–æ–π–∫–∏ –∏ –¥—Ä—É–≥–∏–µ)\\\n",
    "5432 - PostgreSQL database\\\n",
    "6779 - –æ–±—ã—á–Ω—ã–π tcp/udp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü–æ—Ä—Ç –±—É–¥–µ–º –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å –∫–∞–∫ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['destination_port', 'flow_duration', 'total_fwd_packets',\n",
       "       'total_backward_packets', 'total_length_of_fwd_packets',\n",
       "       'total_length_of_bwd_packets', 'fwd_packet_length_max',\n",
       "       'fwd_packet_length_min', 'fwd_packet_length_mean',\n",
       "       'fwd_packet_length_std', 'bwd_packet_length_max',\n",
       "       'bwd_packet_length_min', 'bwd_packet_length_mean',\n",
       "       'bwd_packet_length_std', 'flow_bytes/s', 'flow_packets/s',\n",
       "       'flow_iat_mean', 'flow_iat_std', 'flow_iat_max', 'flow_iat_min',\n",
       "       'fwd_iat_total', 'fwd_iat_mean', 'fwd_iat_std', 'fwd_iat_max',\n",
       "       'fwd_iat_min', 'bwd_iat_total', 'bwd_iat_mean', 'bwd_iat_std',\n",
       "       'bwd_iat_max', 'bwd_iat_min', 'fwd_psh_flags', 'fwd_urg_flags',\n",
       "       'fwd_header_length', 'bwd_header_length', 'fwd_packets/s',\n",
       "       'bwd_packets/s', 'min_packet_length', 'max_packet_length',\n",
       "       'packet_length_mean', 'packet_length_std', 'packet_length_variance',\n",
       "       'fin_flag_count', 'syn_flag_count', 'rst_flag_count', 'psh_flag_count',\n",
       "       'ack_flag_count', 'urg_flag_count', 'cwe_flag_count', 'ece_flag_count',\n",
       "       'down/up_ratio', 'average_packet_size', 'avg_fwd_segment_size',\n",
       "       'avg_bwd_segment_size', 'fwd_header_length.1', 'subflow_fwd_packets',\n",
       "       'subflow_fwd_bytes', 'subflow_bwd_packets', 'subflow_bwd_bytes',\n",
       "       'init_win_bytes_forward', 'init_win_bytes_backward', 'act_data_pkt_fwd',\n",
       "       'min_seg_size_forward', 'active_mean', 'active_std', 'active_max',\n",
       "       'active_min', 'idle_mean', 'idle_std', 'idle_max', 'idle_min', 'label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BENIGN': 0,\n",
       " 'PortScan': 1,\n",
       " 'DoS Hulk': 2,\n",
       " 'DDoS': 3,\n",
       " 'Bot': 4,\n",
       " 'Infiltration': 5,\n",
       " 'Web Attack ÔøΩ Brute Force': 6,\n",
       " 'Web Attack ÔøΩ XSS': 7,\n",
       " 'Web Attack ÔøΩ Sql Injection': 8,\n",
       " 'FTP-Patator': 9,\n",
       " 'SSH-Patator': 10,\n",
       " 'DoS slowloris': 11,\n",
       " 'DoS Slowhttptest': 12,\n",
       " 'DoS GoldenEye': 13,\n",
       " 'Heartbleed': 14}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = {}\n",
    "for num, i in enumerate(df['label'].unique()):\n",
    "    labels[i] = num\n",
    "\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = df['label'].map(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "init_win_bytes_backward        168538\n",
       "init_win_bytes_forward         103039\n",
       "flow_iat_min                      402\n",
       "flow_iat_max                       19\n",
       "flow_iat_mean                      19\n",
       "flow_duration                      19\n",
       "flow_packets/s                     19\n",
       "flow_bytes/s                       15\n",
       "fwd_iat_min                         8\n",
       "min_seg_size_forward                5\n",
       "fwd_header_length                   5\n",
       "bwd_header_length                   5\n",
       "fwd_header_length.1                 5\n",
       "urg_flag_count                      0\n",
       "cwe_flag_count                      0\n",
       "avg_bwd_segment_size                0\n",
       "ack_flag_count                      0\n",
       "psh_flag_count                      0\n",
       "ece_flag_count                      0\n",
       "rst_flag_count                      0\n",
       "syn_flag_count                      0\n",
       "down/up_ratio                       0\n",
       "average_packet_size                 0\n",
       "avg_fwd_segment_size                0\n",
       "destination_port                    0\n",
       "subflow_bwd_packets                 0\n",
       "subflow_fwd_packets                 0\n",
       "subflow_fwd_bytes                   0\n",
       "packet_length_variance              0\n",
       "subflow_bwd_bytes                   0\n",
       "act_data_pkt_fwd                    0\n",
       "active_mean                         0\n",
       "active_std                          0\n",
       "active_max                          0\n",
       "active_min                          0\n",
       "idle_mean                           0\n",
       "idle_std                            0\n",
       "idle_max                            0\n",
       "idle_min                            0\n",
       "fin_flag_count                      0\n",
       "bwd_packets/s                       0\n",
       "packet_length_std                   0\n",
       "packet_length_mean                  0\n",
       "total_fwd_packets                   0\n",
       "total_backward_packets              0\n",
       "total_length_of_fwd_packets         0\n",
       "total_length_of_bwd_packets         0\n",
       "fwd_packet_length_max               0\n",
       "fwd_packet_length_min               0\n",
       "fwd_packet_length_mean              0\n",
       "fwd_packet_length_std               0\n",
       "bwd_packet_length_max               0\n",
       "bwd_packet_length_min               0\n",
       "bwd_packet_length_mean              0\n",
       "bwd_packet_length_std               0\n",
       "flow_iat_std                        0\n",
       "fwd_iat_total                       0\n",
       "fwd_iat_mean                        0\n",
       "fwd_iat_std                         0\n",
       "fwd_iat_max                         0\n",
       "bwd_iat_total                       0\n",
       "bwd_iat_mean                        0\n",
       "bwd_iat_std                         0\n",
       "bwd_iat_max                         0\n",
       "bwd_iat_min                         0\n",
       "fwd_psh_flags                       0\n",
       "fwd_urg_flags                       0\n",
       "fwd_packets/s                       0\n",
       "min_packet_length                   0\n",
       "max_packet_length                   0\n",
       "label                               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df < 0).sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "destination_port                 0\n",
       "flow_duration                    0\n",
       "total_fwd_packets                0\n",
       "total_backward_packets           0\n",
       "total_length_of_fwd_packets      0\n",
       "total_length_of_bwd_packets      0\n",
       "fwd_packet_length_max            0\n",
       "fwd_packet_length_min            0\n",
       "fwd_packet_length_mean           0\n",
       "fwd_packet_length_std            0\n",
       "bwd_packet_length_max            0\n",
       "bwd_packet_length_min            0\n",
       "bwd_packet_length_mean           0\n",
       "bwd_packet_length_std            0\n",
       "flow_bytes/s                   262\n",
       "flow_packets/s                 262\n",
       "flow_iat_mean                    0\n",
       "flow_iat_std                     0\n",
       "flow_iat_max                     0\n",
       "flow_iat_min                     0\n",
       "fwd_iat_total                    0\n",
       "fwd_iat_mean                     0\n",
       "fwd_iat_std                      0\n",
       "fwd_iat_max                      0\n",
       "fwd_iat_min                      0\n",
       "bwd_iat_total                    0\n",
       "bwd_iat_mean                     0\n",
       "bwd_iat_std                      0\n",
       "bwd_iat_max                      0\n",
       "bwd_iat_min                      0\n",
       "fwd_psh_flags                    0\n",
       "fwd_urg_flags                    0\n",
       "fwd_header_length                0\n",
       "bwd_header_length                0\n",
       "fwd_packets/s                    0\n",
       "bwd_packets/s                    0\n",
       "min_packet_length                0\n",
       "max_packet_length                0\n",
       "packet_length_mean               0\n",
       "packet_length_std                0\n",
       "packet_length_variance           0\n",
       "fin_flag_count                   0\n",
       "syn_flag_count                   0\n",
       "rst_flag_count                   0\n",
       "psh_flag_count                   0\n",
       "ack_flag_count                   0\n",
       "urg_flag_count                   0\n",
       "cwe_flag_count                   0\n",
       "ece_flag_count                   0\n",
       "down/up_ratio                    0\n",
       "average_packet_size              0\n",
       "avg_fwd_segment_size             0\n",
       "avg_bwd_segment_size             0\n",
       "fwd_header_length.1              0\n",
       "subflow_fwd_packets              0\n",
       "subflow_fwd_bytes                0\n",
       "subflow_bwd_packets              0\n",
       "subflow_bwd_bytes                0\n",
       "init_win_bytes_forward           0\n",
       "init_win_bytes_backward          0\n",
       "act_data_pkt_fwd                 0\n",
       "min_seg_size_forward             0\n",
       "active_mean                      0\n",
       "active_std                       0\n",
       "active_max                       0\n",
       "active_min                       0\n",
       "idle_mean                        0\n",
       "idle_std                         0\n",
       "idle_max                         0\n",
       "idle_min                         0\n",
       "label                            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–û—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –Ω–µ –¥–æ–ª–∂–Ω—ã –≤—Å—Ç—Ä–µ—á–∞—Ç—å—Å—è —Å—É–¥—è –ø–æ –æ–ø–∏—Å–∞–Ω–∏—é –¥–∞–Ω–Ω—ã—Ö. –ü—Ä–µ–¥–ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–æ, —É—á–∏—Ç—ã–≤–∞—è –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ NaN –≤ –¥–∞—Ç–∞—Å–µ—Ç–µ, –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏ –∑–∞–º–µ–Ω–µ–Ω—ã –ø—Ä–æ–ø—É—Å–∫–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 475015 entries, 0 to 539615\n",
      "Data columns (total 71 columns):\n",
      " #   Column                       Non-Null Count   Dtype  \n",
      "---  ------                       --------------   -----  \n",
      " 0   destination_port             475015 non-null  int64  \n",
      " 1   flow_duration                475015 non-null  int64  \n",
      " 2   total_fwd_packets            475015 non-null  int64  \n",
      " 3   total_backward_packets       475015 non-null  int64  \n",
      " 4   total_length_of_fwd_packets  475015 non-null  int64  \n",
      " 5   total_length_of_bwd_packets  475015 non-null  int64  \n",
      " 6   fwd_packet_length_max        475015 non-null  int64  \n",
      " 7   fwd_packet_length_min        475015 non-null  int64  \n",
      " 8   fwd_packet_length_mean       475015 non-null  float64\n",
      " 9   fwd_packet_length_std        475015 non-null  float64\n",
      " 10  bwd_packet_length_max        475015 non-null  int64  \n",
      " 11  bwd_packet_length_min        475015 non-null  int64  \n",
      " 12  bwd_packet_length_mean       475015 non-null  float64\n",
      " 13  bwd_packet_length_std        475015 non-null  float64\n",
      " 14  flow_bytes/s                 474753 non-null  float64\n",
      " 15  flow_packets/s               474753 non-null  float64\n",
      " 16  flow_iat_mean                475015 non-null  float64\n",
      " 17  flow_iat_std                 475015 non-null  float64\n",
      " 18  flow_iat_max                 475015 non-null  int64  \n",
      " 19  flow_iat_min                 475015 non-null  int64  \n",
      " 20  fwd_iat_total                475015 non-null  int64  \n",
      " 21  fwd_iat_mean                 475015 non-null  float64\n",
      " 22  fwd_iat_std                  475015 non-null  float64\n",
      " 23  fwd_iat_max                  475015 non-null  int64  \n",
      " 24  fwd_iat_min                  475015 non-null  int64  \n",
      " 25  bwd_iat_total                475015 non-null  int64  \n",
      " 26  bwd_iat_mean                 475015 non-null  float64\n",
      " 27  bwd_iat_std                  475015 non-null  float64\n",
      " 28  bwd_iat_max                  475015 non-null  int64  \n",
      " 29  bwd_iat_min                  475015 non-null  int64  \n",
      " 30  fwd_psh_flags                475015 non-null  int64  \n",
      " 31  fwd_urg_flags                475015 non-null  int64  \n",
      " 32  fwd_header_length            475015 non-null  int64  \n",
      " 33  bwd_header_length            475015 non-null  int64  \n",
      " 34  fwd_packets/s                475015 non-null  float64\n",
      " 35  bwd_packets/s                475015 non-null  float64\n",
      " 36  min_packet_length            475015 non-null  int64  \n",
      " 37  max_packet_length            475015 non-null  int64  \n",
      " 38  packet_length_mean           475015 non-null  float64\n",
      " 39  packet_length_std            475015 non-null  float64\n",
      " 40  packet_length_variance       475015 non-null  float64\n",
      " 41  fin_flag_count               475015 non-null  int64  \n",
      " 42  syn_flag_count               475015 non-null  int64  \n",
      " 43  rst_flag_count               475015 non-null  int64  \n",
      " 44  psh_flag_count               475015 non-null  int64  \n",
      " 45  ack_flag_count               475015 non-null  int64  \n",
      " 46  urg_flag_count               475015 non-null  int64  \n",
      " 47  cwe_flag_count               475015 non-null  int64  \n",
      " 48  ece_flag_count               475015 non-null  int64  \n",
      " 49  down/up_ratio                475015 non-null  int64  \n",
      " 50  average_packet_size          475015 non-null  float64\n",
      " 51  avg_fwd_segment_size         475015 non-null  float64\n",
      " 52  avg_bwd_segment_size         475015 non-null  float64\n",
      " 53  fwd_header_length.1          475015 non-null  int64  \n",
      " 54  subflow_fwd_packets          475015 non-null  int64  \n",
      " 55  subflow_fwd_bytes            475015 non-null  int64  \n",
      " 56  subflow_bwd_packets          475015 non-null  int64  \n",
      " 57  subflow_bwd_bytes            475015 non-null  int64  \n",
      " 58  init_win_bytes_forward       475015 non-null  int64  \n",
      " 59  init_win_bytes_backward      475015 non-null  int64  \n",
      " 60  act_data_pkt_fwd             475015 non-null  int64  \n",
      " 61  min_seg_size_forward         475015 non-null  int64  \n",
      " 62  active_mean                  475015 non-null  float64\n",
      " 63  active_std                   475015 non-null  float64\n",
      " 64  active_max                   475015 non-null  int64  \n",
      " 65  active_min                   475015 non-null  int64  \n",
      " 66  idle_mean                    475015 non-null  float64\n",
      " 67  idle_std                     475015 non-null  float64\n",
      " 68  idle_max                     475015 non-null  int64  \n",
      " 69  idle_min                     475015 non-null  int64  \n",
      " 70  label                        475015 non-null  int64  \n",
      "dtypes: float64(24), int64(47)\n",
      "memory usage: 260.9 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–û–±—É—á–∞—é—â–∞—è –≤—ã–±–æ—Ä–∫–∞:\n",
      "–î–æ–ª—è –æ—Ç –æ–±—â–µ–≥–æ —Ä–∞–∑–º–µ—Ä–∞: 0.8\n",
      "C—Ç—Ä–æ–∫, —Å—Ç–æ–ª–±—Ü–æ–≤: (380012, 70)\n",
      "–î–æ–ª—è —Ü–µ–ª–µ–≤–æ–≥–æ –ø—Ä–∏–∑–Ω–∞–∫–∞: 1.657\n",
      "- - - - - - - - - - \n",
      "–¢–µ—Å—Ç–æ–≤–∞—è –≤—ã–±–æ—Ä–∫–∞:\n",
      "–î–æ–ª—è –æ—Ç –æ–±—â–µ–≥–æ —Ä–∞–∑–º–µ—Ä–∞: 0.2\n",
      "C—Ç—Ä–æ–∫, —Å—Ç–æ–ª–±—Ü–æ–≤: (95003, 70)\n",
      "–î–æ–ª—è —Ü–µ–ª–µ–≤–æ–≥–æ –ø—Ä–∏–∑–Ω–∞–∫–∞: 1.657\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "\n",
    "df.fillna(-1, inplace=True)\n",
    "df.replace([np.inf, -np.inf], 0, inplace=True)\n",
    "\n",
    "X, y = df.drop('label', axis=1), df['label'] \n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=TEST_SIZE, \n",
    "    random_state=RANDOM_STATE,\n",
    "    shuffle=True,\n",
    "    stratify=df['label']\n",
    "    )\n",
    "\n",
    "print('–û–±—É—á–∞—é—â–∞—è –≤—ã–±–æ—Ä–∫–∞:')\n",
    "print('–î–æ–ª—è –æ—Ç –æ–±—â–µ–≥–æ —Ä–∞–∑–º–µ—Ä–∞:', round(y_train.shape[0]/X.shape[0], 2))\n",
    "print('C—Ç—Ä–æ–∫, —Å—Ç–æ–ª–±—Ü–æ–≤:', X_train.shape)\n",
    "print('–î–æ–ª—è —Ü–µ–ª–µ–≤–æ–≥–æ –ø—Ä–∏–∑–Ω–∞–∫–∞:', round(y_train.mean(), 3))\n",
    "print('- '*10)\n",
    "\n",
    "\n",
    "print('–¢–µ—Å—Ç–æ–≤–∞—è –≤—ã–±–æ—Ä–∫–∞:')\n",
    "print('–î–æ–ª—è –æ—Ç –æ–±—â–µ–≥–æ —Ä–∞–∑–º–µ—Ä–∞:', round(y_test.shape[0]/X.shape[0], 2))\n",
    "print('C—Ç—Ä–æ–∫, —Å—Ç–æ–ª–±—Ü–æ–≤:', X_test.shape)\n",
    "print('–î–æ–ª—è —Ü–µ–ª–µ–≤–æ–≥–æ –ø—Ä–∏–∑–Ω–∞–∫–∞:', round(y_test.mean(), 3))\n",
    "print('-'*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏: ['destination_port']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ß–∏—Å–ª–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏: ['ack_flag_count', 'subflow_bwd_packets', 'fwd_iat_std', 'packet_length_variance', 'active_max', 'init_win_bytes_backward', 'fwd_packets/s', 'flow_iat_min', 'bwd_iat_std', 'fwd_header_length.1', 'avg_fwd_segment_size', 'packet_length_std', 'act_data_pkt_fwd', 'idle_mean', 'ece_flag_count', 'bwd_iat_max', 'fwd_psh_flags', 'idle_max', 'total_fwd_packets', 'idle_min', 'min_packet_length', 'fwd_packet_length_min', 'flow_bytes/s', 'active_mean', 'syn_flag_count', 'active_std', 'total_length_of_bwd_packets', 'bwd_header_length', 'fwd_packet_length_max', 'bwd_iat_min', 'min_seg_size_forward', 'subflow_bwd_bytes', 'down/up_ratio', 'subflow_fwd_packets', 'idle_std', 'flow_iat_mean', 'subflow_fwd_bytes', 'max_packet_length', 'fin_flag_count', 'fwd_header_length', 'fwd_urg_flags', 'cwe_flag_count', 'packet_length_mean', 'urg_flag_count', 'bwd_packet_length_std', 'flow_duration', 'avg_bwd_segment_size', 'fwd_iat_mean', 'psh_flag_count', 'fwd_packet_length_mean', 'active_min', 'fwd_iat_max', 'flow_packets/s', 'bwd_iat_total', 'flow_iat_std', 'bwd_packet_length_max', 'bwd_packets/s', 'init_win_bytes_forward', 'total_length_of_fwd_packets', 'total_backward_packets', 'bwd_packet_length_mean', 'fwd_iat_min', 'bwd_packet_length_min', 'flow_iat_max', 'rst_flag_count', 'average_packet_size', 'bwd_iat_mean', 'fwd_iat_total', 'fwd_packet_length_std']\n"
     ]
    }
   ],
   "source": [
    "#categorical = list(X_train.select_dtypes('object').columns)\n",
    "categorical = ['destination_port']\n",
    "print(f\"–ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏: {categorical}\")\n",
    "\n",
    "numerical = list(set(X_train.select_dtypes('number').columns) - set(categorical))\n",
    "print(f\"–ß–∏—Å–ª–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏: {numerical}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import QuantileTransformer, PowerTransformer, Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_pipe = Pipeline([('encoder', OneHotEncoder(handle_unknown='ignore'))])\n",
    "num_pipe = Pipeline([('scaler', MinMaxScaler())])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    [\n",
    "        ('cat', cat_pipe, categorical),\n",
    "        ('num', num_pipe, numerical),  # 0.888529\n",
    "    ], remainder='passthrough')\n",
    "\n",
    "pipe = Pipeline(\n",
    "    [\n",
    "        ('preprocessor', preprocessor),\n",
    "        (\"regressor\", XGBClassifier)\n",
    "    ]\n",
    ")\n",
    "\n",
    "param_grid = [{'regressor': [XGBClassifier(\n",
    "    random_seed=RANDOM_STATE, \n",
    "    objective='multi:softmax')],\n",
    "    'regressor__maxdepth': range(5, 8, 1),\n",
    "    }]\n",
    "\n",
    "grid = RandomizedSearchCV(pipe, param_grid, n_iter=3,\n",
    "                          cv=5, scoring='f1_macro', verbose=3, random_state=RANDOM_STATE, n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "[CV 1/5] END regressor=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, objective='multi:softmax', ...), regressor__maxdepth=5;, score=0.933 total time= 1.2min\n",
      "[CV 2/5] END regressor=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, objective='multi:softmax', ...), regressor__maxdepth=5;, score=0.916 total time= 1.3min\n",
      "[CV 3/5] END regressor=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, objective='multi:softmax', ...), regressor__maxdepth=5;, score=0.923 total time= 1.3min\n",
      "[CV 4/5] END regressor=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, objective='multi:softmax', ...), regressor__maxdepth=5;, score=0.903 total time= 1.3min\n",
      "[CV 5/5] END regressor=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, objective='multi:softmax', ...), regressor__maxdepth=5;, score=0.901 total time= 1.3min\n",
      "[CV 1/5] END regressor=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, objective='multi:softmax', ...), regressor__maxdepth=6;, score=0.933 total time= 1.4min\n",
      "[CV 2/5] END regressor=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, objective='multi:softmax', ...), regressor__maxdepth=6;, score=0.916 total time= 1.3min\n",
      "[CV 3/5] END regressor=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, objective='multi:softmax', ...), regressor__maxdepth=6;, score=0.923 total time= 1.4min\n",
      "[CV 4/5] END regressor=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, objective='multi:softmax', ...), regressor__maxdepth=6;, score=0.903 total time= 1.3min\n",
      "[CV 5/5] END regressor=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, objective='multi:softmax', ...), regressor__maxdepth=6;, score=0.901 total time= 1.4min\n",
      "[CV 1/5] END regressor=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, objective='multi:softmax', ...), regressor__maxdepth=7;, score=0.933 total time= 1.3min\n",
      "[CV 2/5] END regressor=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, objective='multi:softmax', ...), regressor__maxdepth=7;, score=0.916 total time= 1.2min\n",
      "[CV 3/5] END regressor=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, objective='multi:softmax', ...), regressor__maxdepth=7;, score=0.923 total time= 1.4min\n",
      "[CV 4/5] END regressor=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, objective='multi:softmax', ...), regressor__maxdepth=7;, score=0.903 total time= 1.3min\n",
      "[CV 5/5] END regressor=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, objective='multi:softmax', ...), regressor__maxdepth=7;, score=0.901 total time= 1.1min\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                                              ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                                                transformers=[(&#x27;cat&#x27;,\n",
       "                                                                               Pipeline(steps=[(&#x27;encoder&#x27;,\n",
       "                                                                                                OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                                                               [&#x27;destination_port&#x27;]),\n",
       "                                                                              (&#x27;num&#x27;,\n",
       "                                                                               Pipeline(steps=[(&#x27;scaler&#x27;,\n",
       "                                                                                                MinMaxScaler())]),\n",
       "                                                                               [&#x27;ack_flag_count&#x27;,\n",
       "                                                                                &#x27;subflow_bwd_packets&#x27;,\n",
       "                                                                                &#x27;fwd_iat_std&#x27;,\n",
       "                                                                                &#x27;packet_length_variance&#x27;,...\n",
       "                                                                     max_bin=None,\n",
       "                                                                     max_cat_threshold=None,\n",
       "                                                                     max_cat_to_onehot=None,\n",
       "                                                                     max_delta_step=None,\n",
       "                                                                     max_depth=None,\n",
       "                                                                     max_leaves=None,\n",
       "                                                                     min_child_weight=None,\n",
       "                                                                     missing=nan,\n",
       "                                                                     monotone_constraints=None,\n",
       "                                                                     multi_strategy=None,\n",
       "                                                                     n_estimators=None,\n",
       "                                                                     n_jobs=None,\n",
       "                                                                     num_parallel_tree=None,\n",
       "                                                                     objective=&#x27;multi:softmax&#x27;, ...)],\n",
       "                                         &#x27;regressor__maxdepth&#x27;: range(5, 8)}],\n",
       "                   random_state=42, scoring=&#x27;f1_macro&#x27;, verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                                              ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                                                transformers=[(&#x27;cat&#x27;,\n",
       "                                                                               Pipeline(steps=[(&#x27;encoder&#x27;,\n",
       "                                                                                                OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                                                               [&#x27;destination_port&#x27;]),\n",
       "                                                                              (&#x27;num&#x27;,\n",
       "                                                                               Pipeline(steps=[(&#x27;scaler&#x27;,\n",
       "                                                                                                MinMaxScaler())]),\n",
       "                                                                               [&#x27;ack_flag_count&#x27;,\n",
       "                                                                                &#x27;subflow_bwd_packets&#x27;,\n",
       "                                                                                &#x27;fwd_iat_std&#x27;,\n",
       "                                                                                &#x27;packet_length_variance&#x27;,...\n",
       "                                                                     max_bin=None,\n",
       "                                                                     max_cat_threshold=None,\n",
       "                                                                     max_cat_to_onehot=None,\n",
       "                                                                     max_delta_step=None,\n",
       "                                                                     max_depth=None,\n",
       "                                                                     max_leaves=None,\n",
       "                                                                     min_child_weight=None,\n",
       "                                                                     missing=nan,\n",
       "                                                                     monotone_constraints=None,\n",
       "                                                                     multi_strategy=None,\n",
       "                                                                     n_estimators=None,\n",
       "                                                                     n_jobs=None,\n",
       "                                                                     num_parallel_tree=None,\n",
       "                                                                     objective=&#x27;multi:softmax&#x27;, ...)],\n",
       "                                         &#x27;regressor__maxdepth&#x27;: range(5, 8)}],\n",
       "                   random_state=42, scoring=&#x27;f1_macro&#x27;, verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;cat&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;encoder&#x27;,\n",
       "                                                                   OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                                  [&#x27;destination_port&#x27;]),\n",
       "                                                 (&#x27;num&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;scaler&#x27;,\n",
       "                                                                   MinMaxScaler())]),\n",
       "                                                  [&#x27;ack_flag_count&#x27;,\n",
       "                                                   &#x27;subflow_bwd_packets&#x27;,\n",
       "                                                   &#x27;fwd_iat_std&#x27;,\n",
       "                                                   &#x27;packet_length_variance&#x27;,\n",
       "                                                   &#x27;active_max&#x27;,\n",
       "                                                   &#x27;init_win_bytes_backw...\n",
       "                                                   &#x27;idle_mean&#x27;,\n",
       "                                                   &#x27;ece_flag_count&#x27;,\n",
       "                                                   &#x27;bwd_iat_max&#x27;,\n",
       "                                                   &#x27;fwd_psh_flags&#x27;, &#x27;idle_max&#x27;,\n",
       "                                                   &#x27;total_fwd_packets&#x27;,\n",
       "                                                   &#x27;idle_min&#x27;,\n",
       "                                                   &#x27;min_packet_length&#x27;,\n",
       "                                                   &#x27;fwd_packet_length_min&#x27;,\n",
       "                                                   &#x27;flow_bytes/s&#x27;,\n",
       "                                                   &#x27;active_mean&#x27;,\n",
       "                                                   &#x27;syn_flag_count&#x27;,\n",
       "                                                   &#x27;active_std&#x27;,\n",
       "                                                   &#x27;total_length_of_bwd_packets&#x27;,\n",
       "                                                   &#x27;bwd_header_length&#x27;,\n",
       "                                                   &#x27;fwd_packet_length_max&#x27;,\n",
       "                                                   &#x27;bwd_iat_min&#x27;, ...])])),\n",
       "                (&#x27;regressor&#x27;, &lt;class &#x27;xgboost.sklearn.XGBClassifier&#x27;&gt;)])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessor: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                  transformers=[(&#x27;cat&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;encoder&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                 [&#x27;destination_port&#x27;]),\n",
       "                                (&#x27;num&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;scaler&#x27;, MinMaxScaler())]),\n",
       "                                 [&#x27;ack_flag_count&#x27;, &#x27;subflow_bwd_packets&#x27;,\n",
       "                                  &#x27;fwd_iat_std&#x27;, &#x27;packet_length_variance&#x27;,\n",
       "                                  &#x27;active_max&#x27;, &#x27;init_win_bytes_backward&#x27;,\n",
       "                                  &#x27;fwd_packets/s&#x27;, &#x27;flow_iat_m...\n",
       "                                  &#x27;avg_fwd_segment_size&#x27;, &#x27;packet_length_std&#x27;,\n",
       "                                  &#x27;act_data_pkt_fwd&#x27;, &#x27;idle_mean&#x27;,\n",
       "                                  &#x27;ece_flag_count&#x27;, &#x27;bwd_iat_max&#x27;,\n",
       "                                  &#x27;fwd_psh_flags&#x27;, &#x27;idle_max&#x27;,\n",
       "                                  &#x27;total_fwd_packets&#x27;, &#x27;idle_min&#x27;,\n",
       "                                  &#x27;min_packet_length&#x27;, &#x27;fwd_packet_length_min&#x27;,\n",
       "                                  &#x27;flow_bytes/s&#x27;, &#x27;active_mean&#x27;,\n",
       "                                  &#x27;syn_flag_count&#x27;, &#x27;active_std&#x27;,\n",
       "                                  &#x27;total_length_of_bwd_packets&#x27;,\n",
       "                                  &#x27;bwd_header_length&#x27;, &#x27;fwd_packet_length_max&#x27;,\n",
       "                                  &#x27;bwd_iat_min&#x27;, ...])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">cat</label><div class=\"sk-toggleable__content\"><pre>[&#x27;destination_port&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">num</label><div class=\"sk-toggleable__content\"><pre>[&#x27;ack_flag_count&#x27;, &#x27;subflow_bwd_packets&#x27;, &#x27;fwd_iat_std&#x27;, &#x27;packet_length_variance&#x27;, &#x27;active_max&#x27;, &#x27;init_win_bytes_backward&#x27;, &#x27;fwd_packets/s&#x27;, &#x27;flow_iat_min&#x27;, &#x27;bwd_iat_std&#x27;, &#x27;fwd_header_length.1&#x27;, &#x27;avg_fwd_segment_size&#x27;, &#x27;packet_length_std&#x27;, &#x27;act_data_pkt_fwd&#x27;, &#x27;idle_mean&#x27;, &#x27;ece_flag_count&#x27;, &#x27;bwd_iat_max&#x27;, &#x27;fwd_psh_flags&#x27;, &#x27;idle_max&#x27;, &#x27;total_fwd_packets&#x27;, &#x27;idle_min&#x27;, &#x27;min_packet_length&#x27;, &#x27;fwd_packet_length_min&#x27;, &#x27;flow_bytes/s&#x27;, &#x27;active_mean&#x27;, &#x27;syn_flag_count&#x27;, &#x27;active_std&#x27;, &#x27;total_length_of_bwd_packets&#x27;, &#x27;bwd_header_length&#x27;, &#x27;fwd_packet_length_max&#x27;, &#x27;bwd_iat_min&#x27;, &#x27;min_seg_size_forward&#x27;, &#x27;subflow_bwd_bytes&#x27;, &#x27;down/up_ratio&#x27;, &#x27;subflow_fwd_packets&#x27;, &#x27;idle_std&#x27;, &#x27;flow_iat_mean&#x27;, &#x27;subflow_fwd_bytes&#x27;, &#x27;max_packet_length&#x27;, &#x27;fin_flag_count&#x27;, &#x27;fwd_header_length&#x27;, &#x27;fwd_urg_flags&#x27;, &#x27;cwe_flag_count&#x27;, &#x27;packet_length_mean&#x27;, &#x27;urg_flag_count&#x27;, &#x27;bwd_packet_length_std&#x27;, &#x27;flow_duration&#x27;, &#x27;avg_bwd_segment_size&#x27;, &#x27;fwd_iat_mean&#x27;, &#x27;psh_flag_count&#x27;, &#x27;fwd_packet_length_mean&#x27;, &#x27;active_min&#x27;, &#x27;fwd_iat_max&#x27;, &#x27;flow_packets/s&#x27;, &#x27;bwd_iat_total&#x27;, &#x27;flow_iat_std&#x27;, &#x27;bwd_packet_length_max&#x27;, &#x27;bwd_packets/s&#x27;, &#x27;init_win_bytes_forward&#x27;, &#x27;total_length_of_fwd_packets&#x27;, &#x27;total_backward_packets&#x27;, &#x27;bwd_packet_length_mean&#x27;, &#x27;fwd_iat_min&#x27;, &#x27;bwd_packet_length_min&#x27;, &#x27;flow_iat_max&#x27;, &#x27;rst_flag_count&#x27;, &#x27;average_packet_size&#x27;, &#x27;bwd_iat_mean&#x27;, &#x27;fwd_iat_total&#x27;, &#x27;fwd_packet_length_std&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">remainder</label><div class=\"sk-toggleable__content\"><pre></pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">type</label><div class=\"sk-toggleable__content\"><pre>&lt;class &#x27;xgboost.sklearn.XGBClassifier&#x27;&gt;</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[('preprocessor',\n",
       "                                              ColumnTransformer(remainder='passthrough',\n",
       "                                                                transformers=[('cat',\n",
       "                                                                               Pipeline(steps=[('encoder',\n",
       "                                                                                                OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                                               ['destination_port']),\n",
       "                                                                              ('num',\n",
       "                                                                               Pipeline(steps=[('scaler',\n",
       "                                                                                                MinMaxScaler())]),\n",
       "                                                                               ['ack_flag_count',\n",
       "                                                                                'subflow_bwd_packets',\n",
       "                                                                                'fwd_iat_std',\n",
       "                                                                                'packet_length_variance',...\n",
       "                                                                     max_bin=None,\n",
       "                                                                     max_cat_threshold=None,\n",
       "                                                                     max_cat_to_onehot=None,\n",
       "                                                                     max_delta_step=None,\n",
       "                                                                     max_depth=None,\n",
       "                                                                     max_leaves=None,\n",
       "                                                                     min_child_weight=None,\n",
       "                                                                     missing=nan,\n",
       "                                                                     monotone_constraints=None,\n",
       "                                                                     multi_strategy=None,\n",
       "                                                                     n_estimators=None,\n",
       "                                                                     n_jobs=None,\n",
       "                                                                     num_parallel_tree=None,\n",
       "                                                                     objective='multi:softmax', ...)],\n",
       "                                         'regressor__maxdepth': range(5, 8)}],\n",
       "                   random_state=42, scoring='f1_macro', verbose=3)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_regressor__maxdepth</th>\n",
       "      <th>param_regressor</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>73.72</td>\n",
       "      <td>1.72</td>\n",
       "      <td>2.35</td>\n",
       "      <td>0.27</td>\n",
       "      <td>5</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>{'regressor__maxdepth': 5, 'regressor': XGBCla...</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>79.37</td>\n",
       "      <td>1.64</td>\n",
       "      <td>2.48</td>\n",
       "      <td>0.11</td>\n",
       "      <td>6</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>{'regressor__maxdepth': 6, 'regressor': XGBCla...</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>72.31</td>\n",
       "      <td>3.92</td>\n",
       "      <td>2.36</td>\n",
       "      <td>0.36</td>\n",
       "      <td>7</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>{'regressor__maxdepth': 7, 'regressor': XGBCla...</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          73.72          1.72             2.35            0.27   \n",
       "1          79.37          1.64             2.48            0.11   \n",
       "2          72.31          3.92             2.36            0.36   \n",
       "\n",
       "  param_regressor__maxdepth  \\\n",
       "0                         5   \n",
       "1                         6   \n",
       "2                         7   \n",
       "\n",
       "                                     param_regressor  \\\n",
       "0  XGBClassifier(base_score=None, booster=None, c...   \n",
       "1  XGBClassifier(base_score=None, booster=None, c...   \n",
       "2  XGBClassifier(base_score=None, booster=None, c...   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'regressor__maxdepth': 5, 'regressor': XGBCla...               0.93   \n",
       "1  {'regressor__maxdepth': 6, 'regressor': XGBCla...               0.93   \n",
       "2  {'regressor__maxdepth': 7, 'regressor': XGBCla...               0.93   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0               0.92               0.92               0.90               0.90   \n",
       "1               0.92               0.92               0.90               0.90   \n",
       "2               0.92               0.92               0.90               0.90   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0             0.92            0.01                1  \n",
       "1             0.92            0.01                1  \n",
       "2             0.92            0.01                1  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.DataFrame(grid.cv_results_)\n",
    "result.sort_values('mean_test_score', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     46562\n",
      "           1       1.00      1.00      1.00     11279\n",
      "           2       1.00      1.00      1.00     17450\n",
      "           3       1.00      1.00      1.00     12873\n",
      "           4       0.94      0.97      0.96       391\n",
      "           5       1.00      1.00      1.00         7\n",
      "           6       0.74      0.86      0.79       294\n",
      "           7       0.53      0.32      0.40       130\n",
      "           8       0.75      0.75      0.75         4\n",
      "           9       1.00      1.00      1.00      1187\n",
      "          10       1.00      1.00      1.00       644\n",
      "          11       1.00      0.99      1.00      1077\n",
      "          12       1.00      1.00      1.00      1046\n",
      "          13       1.00      1.00      1.00      2057\n",
      "          14       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           1.00     95003\n",
      "   macro avg       0.93      0.93      0.93     95003\n",
      "weighted avg       1.00      1.00      1.00     95003\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#target_names = list(label_encoder.inverse_transform(df['label'].unique()))\n",
    "\n",
    "y_pred = grid.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x1440 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "conf_matr = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "plt.rc('font', size=6) #controls default text size\n",
    "plt.figure(figsize=(12, 12), dpi=120)\n",
    "ConfusionMatrixDisplay(confusion_matrix=conf_matr, display_labels=labels.keys()).plot()\n",
    "plt.xticks(rotation=90)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ú–æ–¥–µ–ª—å –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –Ω–µ –ø–ª–æ—Ö–æ –æ–ø—Ä–µ–¥–µ–ª–∏–ª–∞ –∫–ª–∞—Å—Å –∞—Ç–∞–∫. –ù–∞–∏–±–æ–ª—å—à–∞—è –æ—à–∏–±–∫–∞ –º–µ–∂–¥—É –∫–ª–∞—Å—Å–∞–º–∏ Web Attack. –ü—Ä–∏ —ç—Ç–æ–º —Å–∞–º —Ñ–∞–∫—Ç –∞—Ç–∞–∫–∏ —á–∞—â–µ –≤—Å–µ–≥–æ –æ—à–∏–±–æ—á–Ω–æ –æ–ø—Ä–µ–¥–µ–ª–µ—è–µ—Ç—Å—è –ø—Ä–∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–∏–∏ –±–æ—Ç–æ–≤ (Bot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –í—ã–≤–æ–¥\n",
    "\n",
    "–í –¥–∞–Ω–Ω–æ–π —Ä–∞–±–æ—Ç–µ –Ω–∞–º–∏ –ø—Ä–æ–≤–µ–¥–µ–Ω–æ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞ —Å –ª–æ–≥–∞–º–∏ —Å–µ—Ç–µ–≤—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –ø—Ä–∏ —Ä–∞–±–æ—Ç–µ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Å–µ—Ç–µ–≤—ã—Ö –∞—Ç–∞–∫. –ù–∞ –æ—Å–Ω–æ–≤–µ –¥–∞–Ω–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞ –±—ã–ª–∞ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∞ –º–æ–¥–µ–ª—å –æ–ø—Ä–µ–¥–µ–µ–ª–µ–Ω–∏—è —Ç–∏–ø–∞ –∞—Ç–∞–∫–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –º–æ–¥–µ–ª–∏ –≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω–æ–≥–æ –±—É—Å—Ç–∏–Ω–≥–∞ XGBClassifier.\n",
    "\n",
    "–í –¥–∞—Ç–∞—Å–µ—Ç–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã —Å—Ç–æ–ª–±—Ü—ã —Å–æ —Å—Ä–µ–¥–Ω–∏–º–∏, –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–º–∏, –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏, –º–æ–∂–Ω–æ –ø—Ä–µ–¥–ø–æ–ª–æ–∂–∏—Ç—å —á—Ç–æ –¥–∞–Ω–Ω—ã—Ö –∏–∑–±—ã—Ç–æ—á–Ω–æ –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è \"—Ñ–∏—á–µ–π\" –Ω–µ –ø–æ–Ω–∞–¥–æ–±–∏—Ç—Å—è.\n",
    "–ù–∞ —ç—Ç–∞–ø–µ –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ–≥–æ –æ–∑–Ω–∞–∫–æ–º–ª–µ–Ω–∏—è –≤ –¥–∞—Ç–∞—Å–µ—Ç–µ –≤—ã—è–≤–ª–µ–Ω–æ 79 —Å—Ç–æ–ª–±—Ü–æ–≤. –í –¥–∞–ª—å–Ω–µ–π—à–µ–º –∏–∑-–∑–∞ —Ç–æ–≥–æ —á—Ç–æ —Å—Ç–æ–ª–±–µ—Ü –∑–∞–ø–æ–ª–Ω–µ–Ω –æ–¥–∏–Ω–∫–æ–≤—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏ 8 —Å—Ç–æ–ª–±—Ü–æ–≤ –±—ã–ª–∏ —É–¥–∞–ª–µ–Ω—ã.\n",
    "–¢–∞–∫–∂–µ –±—ã–ª–∏ —É–¥–∞–ª–µ–Ω—ã –¥—É–±–ª–∏–∫–∞—Ç—ã. \n",
    "\n",
    "–ü–æ—Ä—Ç –Ω–∞ –∫–æ—Ç–æ—Ä—ã–π –æ—Ç–ø—Ä–∞–≤–ª—è—é—Ç—Å—è –ø–∞–∫–µ—Ç—ã –±—ã–ª–æ —Ä–µ—à–µ–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫–∞–∫ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–π –ø—Ä–∏–∑–Ω–∞–∫.\n",
    "\n",
    "–ù–∞ –æ—Å–Ω–æ–≤–µ XGBClassifier –±—ã–ª —Å–æ–±—Ä–∞–Ω pipeline —Å–æ —Å–ª—É—á–∞–π–Ω—ã–º –ø–æ–¥–±–æ—Ä–æ–º –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ RandomSearchCV\n",
    "–ü–æ—Å–ª–µ –æ–±—É—á–µ–Ω–∏—è –ø—Ä–∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏ –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ –ø–æ–ª—É—á–µ–Ω —Ä–µ–∑–π–ª—å—Ç–∞—Ç —Å –º–µ—Ç—Ä–∏–∫–∏ F1 0.93\n",
    "\n",
    "–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∏—Å–ø–æ–ª—å–∑—É–µ–º–æ–π –º–æ–¥–µ–ª–∏  –ø—Ä–∏–≤–µ–¥–µ–Ω—ã –Ω–∏–∂–µ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'objective': 'multi:softmax',\n",
       " 'base_score': None,\n",
       " 'booster': None,\n",
       " 'colsample_bylevel': None,\n",
       " 'colsample_bynode': None,\n",
       " 'colsample_bytree': None,\n",
       " 'device': None,\n",
       " 'eval_metric': None,\n",
       " 'gamma': None,\n",
       " 'grow_policy': None,\n",
       " 'interaction_constraints': None,\n",
       " 'learning_rate': None,\n",
       " 'max_bin': None,\n",
       " 'max_cat_threshold': None,\n",
       " 'max_cat_to_onehot': None,\n",
       " 'max_delta_step': None,\n",
       " 'max_depth': None,\n",
       " 'max_leaves': None,\n",
       " 'min_child_weight': None,\n",
       " 'monotone_constraints': None,\n",
       " 'multi_strategy': None,\n",
       " 'n_jobs': None,\n",
       " 'num_parallel_tree': None,\n",
       " 'random_state': None,\n",
       " 'reg_alpha': None,\n",
       " 'reg_lambda': None,\n",
       " 'sampling_method': None,\n",
       " 'scale_pos_weight': None,\n",
       " 'subsample': None,\n",
       " 'tree_method': None,\n",
       " 'validate_parameters': None,\n",
       " 'verbosity': None,\n",
       " 'random_seed': 42,\n",
       " 'maxdepth': 5}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_estimator_.named_steps[\"regressor\"].get_xgb_params()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
